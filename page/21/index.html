<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/logo/FlamingBytes-icon-64x64-1.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/logo/FlamingBytes-icon-64x64-1.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/logo/FlamingBytes-icon-64x64-1.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" integrity="sha256-CTSx/A06dm1B063156EVh15m6Y67pAjZZaQc89LLSrU=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"www.flamingbytes.com","root":"/","images":"/images","scheme":"Mist","darkmode":true,"version":"8.18.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":"default"},"fold":{"enable":true,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="Stay hungry, stay foolish">
<meta property="og:type" content="website">
<meta property="og:title" content="FlamingBytes">
<meta property="og:url" content="https://www.flamingbytes.com/page/21/index.html">
<meta property="og:site_name" content="FlamingBytes">
<meta property="og:description" content="Stay hungry, stay foolish">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="relentlesstorm">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://www.flamingbytes.com/page/21/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"en","comments":"","permalink":"","path":"page/21/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>FlamingBytes</title>
  







<!-- Google Adsense-->
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8578408127828851"
     crossorigin="anonymous"></script>

<!-- Google tag (gtag.js) for analytics-->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-B8PQ47L2H0"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-B8PQ47L2H0');
</script>

  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">FlamingBytes</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories<span class="badge">10</span></a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags<span class="badge">103</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives<span class="badge">268</span></a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="relentlesstorm"
      src="/images/logo/FlamingBytes-icon-64x64-1.png">
  <p class="site-author-name" itemprop="name">relentlesstorm</p>
  <div class="site-description" itemprop="description">Stay hungry, stay foolish</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">268</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">103</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="mailto:relentlesstorm@gmail.com" title="E-Mail → mailto:relentlesstorm@gmail.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.flamingbytes.com/blog/backup-and-restore-mysql-database/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/logo/FlamingBytes-icon-64x64-1.png">
      <meta itemprop="name" content="relentlesstorm">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FlamingBytes">
      <meta itemprop="description" content="Stay hungry, stay foolish">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | FlamingBytes">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/blog/backup-and-restore-mysql-database/" class="post-title-link" itemprop="url">Backup and restore MySQL database</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-09-28 07:00:00" itemprop="dateCreated datePublished" datetime="2021-09-28T07:00:00-07:00">2021-09-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-10-22 11:28:20" itemprop="dateModified" datetime="2023-10-22T11:28:20-07:00">2023-10-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Tech/" itemprop="url" rel="index"><span itemprop="name">Tech</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Tech/Big-Data/" itemprop="url" rel="index"><span itemprop="name">Big Data</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="Backup-a-database"><a href="#Backup-a-database" class="headerlink" title="Backup a database"></a>Backup a database</h2><p>mysqldump is a command-line utility which can be used to generate backups of MySQL database.</p>
<pre><code>$ mysqldump -u root --password=&lt;db_password&gt; mydb &gt; mydb_dump_`date +&quot;%Y%m%d_%H%M%S&quot;`.sql
$  ls -ltr | grep mydb
-rw-r--r--.   1 root root 4834575 Sep 28 21:11 mydb_dump_20210928_144610.sql
</code></pre>
<h2 id="Restore-a-database"><a href="#Restore-a-database" class="headerlink" title="Restore a database"></a>Restore a database</h2><p>Create an empty database before restore as below:</p>
<pre><code>$ mysql -u root -p

mysql&gt; create database mydb;
mysql&gt; show databases;
mysql&gt; exit
</code></pre>
<p>Restore the database:</p>
<pre><code>$ mysql -u root -p mydb &lt; mydb_dump_20210928_144610.sql
</code></pre>
<p>Check the database size as below:</p>
<pre><code>mysql&gt; SELECT table_schema &quot;DB Name&quot;, ROUND(SUM(data_length + index_length) / 1024 / 1024, 1) &quot;DB Size in MB&quot;  FROM information_schema.tables  GROUP BY table_schema;
+--------------------+---------------+
| DB Name            | DB Size in MB |
+--------------------+---------------+
| mydb               |           8.1 |
+--------------------+---------------+
</code></pre>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.flamingbytes.com/blog/create-image-gallery-in-jekyll-without-plugin/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/logo/FlamingBytes-icon-64x64-1.png">
      <meta itemprop="name" content="relentlesstorm">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FlamingBytes">
      <meta itemprop="description" content="Stay hungry, stay foolish">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | FlamingBytes">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/blog/create-image-gallery-in-jekyll-without-plugin/" class="post-title-link" itemprop="url">Create Image Gallery in Jekyll without Plugin</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-09-19 07:00:00" itemprop="dateCreated datePublished" datetime="2021-09-19T07:00:00-07:00">2021-09-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-10-22 11:28:20" itemprop="dateModified" datetime="2023-10-22T11:28:20-07:00">2023-10-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Tech/" itemprop="url" rel="index"><span itemprop="name">Tech</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Tech/Blog/" itemprop="url" rel="index"><span itemprop="name">Blog</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>An image gallery can be easily built by using <strong>LightBox</strong> and <strong>Image Gallery</strong> scripts in Jekyll.</p>
<ol>
<li>LightBox</li>
</ol>
<p><a target="_blank" rel="noopener" href="https://jekyllcodex.org/without-plugin/lightbox/">Lightbox</a> is a solution that loads your image links, your Youtube links and your Vimeo links automatically in a minimalistic and responsive pseudo window&#x2F;overlay. No adjustment to your links is required, just follow the instructions to install the css and js script.</p>
<ol start="2">
<li>Image Gallery</li>
</ol>
<p>The script <a target="_blank" rel="noopener" href="https://jekyllcodex.org/without-plugin/image-gallery/">Image Gallery</a> creates an image gallery. The script reads all images from a specific (user-defined) folder in Jekyll, automagically crops them to 300px squares, using an image resize proxy service and shows them in rows of five. Just follow the very easy instrutions to install it and we are good to go.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.flamingbytes.com/blog/using-sysbench-for-oltp-workload-performance-benchmark/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/logo/FlamingBytes-icon-64x64-1.png">
      <meta itemprop="name" content="relentlesstorm">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FlamingBytes">
      <meta itemprop="description" content="Stay hungry, stay foolish">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | FlamingBytes">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/blog/using-sysbench-for-oltp-workload-performance-benchmark/" class="post-title-link" itemprop="url">Using sysbench for OLTP workload performance benchmark</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-09-07 07:00:00" itemprop="dateCreated datePublished" datetime="2021-09-07T07:00:00-07:00">2021-09-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-10-22 11:28:20" itemprop="dateModified" datetime="2023-10-22T11:28:20-07:00">2023-10-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Tech/" itemprop="url" rel="index"><span itemprop="name">Tech</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Tech/Benchmarking/" itemprop="url" rel="index"><span itemprop="name">Benchmarking</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="Intro-to-Sysbench"><a href="#Intro-to-Sysbench" class="headerlink" title="Intro to Sysbench"></a>Intro to Sysbench</h2><p>sysbench is a scriptable multi-threaded benchmark tool based on LuaJIT. It is most frequently used for database benchmarks, but can also be used to create arbitrarily complex workloads that do not involve a database server.</p>
<p>sysbench comes with the following bundled benchmarks:</p>
<ul>
<li>oltp_*.lua: a collection of OLTP-like database benchmarks</li>
<li>fileio: a filesystem-level benchmark</li>
<li>cpu: a simple CPU benchmark</li>
<li>memory: a memory access benchmark</li>
<li>threads: a thread-based scheduler benchmark</li>
<li>mutex: a POSIX mutex benchmark</li>
</ul>
<p>Below is a description of typical test commands and their purpose:</p>
<ul>
<li>prepare: performs preparative actions for those tests which need them, e.g. creating the necessary files on disk for the fileio test, or filling the test database for database benchmarks.</li>
<li>run: runs the actual test specified with the testname argument. This command is provided by all tests.</li>
<li>cleanup: removes temporary data after the test run in those tests which create one.</li>
<li>help: displays usage information for the test specified with the testname argument. This includes the full list of commands provided by the test, so it should be used to get the available commands.</li>
</ul>
<h2 id="Install-sysbench-on-CentOS-7-5"><a href="#Install-sysbench-on-CentOS-7-5" class="headerlink" title="Install sysbench on CentOS 7.5"></a>Install sysbench on CentOS 7.5</h2><pre><code>$ cat /etc/centos-release
CentOS Linux release 7.5.1804 (Core)
$ uname -r
5.7.12-1.el7.elrepo.x86_64

$ curl -s https://packagecloud.io/install/repositories/akopytov/sysbench/script.rpm.sh | sudo bash
$ sudo yum -y install sysbench

$ sysbench --version
sysbench 1.0.20

$ sysbench --help
Usage:
  sysbench [options]... [testname] [command]

Commands implemented by most tests: prepare run cleanup help

General options:
  --threads=N                     number of threads to use [1]
  --events=N                      limit for total number of events [0]
  --time=N                        limit for total execution time in seconds [10]
  --forced-shutdown=STRING        number of seconds to wait after the --time limit before forcing shutdown, or &#39;off&#39; to disable [off]
  --thread-stack-size=SIZE        size of stack per thread [64K]
  --rate=N                        average transactions rate. 0 for unlimited rate [0]
  --report-interval=N             periodically report intermediate statistics with a specified interval in seconds. 0 disables intermediate reports [0]
  --report-checkpoints=[LIST,...] dump full statistics and reset all counters at specified points in time. The argument is a list of comma-separated values representing the amount of time in seconds elapsed from start of test when report checkpoint(s) must be performed. Report checkpoints are off by default. []
  --debug[=on|off]                print more debugging info [off]
  --validate[=on|off]             perform validation checks where possible [off]
  --help[=on|off]                 print help and exit [off]
  --version[=on|off]              print version and exit [off]
  --config-file=FILENAME          File containing command line options
  --tx-rate=N                     deprecated alias for --rate [0]
  --max-requests=N                deprecated alias for --events [0]
  --max-time=N                    deprecated alias for --time [0]
  --num-threads=N                 deprecated alias for --threads [1]

Pseudo-Random Numbers Generator options:
  --rand-type=STRING random numbers distribution &#123;uniform,gaussian,special,pareto&#125; [special]
  --rand-spec-iter=N number of iterations used for numbers generation [12]
  --rand-spec-pct=N  percentage of values to be treated as &#39;special&#39; (for special distribution) [1]
  --rand-spec-res=N  percentage of &#39;special&#39; values to use (for special distribution) [75]
  --rand-seed=N      seed for random number generator. When 0, the current time is used as a RNG seed. [0]
  --rand-pareto-h=N  parameter h for pareto distribution [0.2]

Log options:
  --verbosity=N verbosity level &#123;5 - debug, 0 - only critical messages&#125; [3]

  --percentile=N       percentile to calculate in latency statistics (1-100). Use the special value of 0 to disable percentile calculations [95]
  --histogram[=on|off] print latency histogram in report [off]

General database options:

  --db-driver=STRING  specifies database driver to use (&#39;help&#39; to get list of available drivers) [mysql]
  --db-ps-mode=STRING prepared statements usage mode &#123;auto, disable&#125; [auto]
  --db-debug[=on|off] print database-specific debug information [off]


Compiled-in database drivers:
  mysql - MySQL driver
  pgsql - PostgreSQL driver

mysql options:
  --mysql-host=[LIST,...]          MySQL server host [localhost]
  --mysql-port=[LIST,...]          MySQL server port [3306]
  --mysql-socket=[LIST,...]        MySQL socket
  --mysql-user=STRING              MySQL user [sbtest]
  --mysql-password=STRING          MySQL password []
  --mysql-db=STRING                MySQL database name [sbtest]
  --mysql-ssl[=on|off]             use SSL connections, if available in the client library [off]
  --mysql-ssl-cipher=STRING        use specific cipher for SSL connections []
  --mysql-compression[=on|off]     use compression, if available in the client library [off]
  --mysql-debug[=on|off]           trace all client library calls [off]
  --mysql-ignore-errors=[LIST,...] list of errors to ignore, or &quot;all&quot; [1213,1020,1205]
  --mysql-dry-run[=on|off]         Dry run, pretend that all MySQL client API calls are successful without executing them [off]

pgsql options:
  --pgsql-host=STRING     PostgreSQL server host [localhost]
  --pgsql-port=N          PostgreSQL server port [5432]
  --pgsql-user=STRING     PostgreSQL user [sbtest]
  --pgsql-password=STRING PostgreSQL password []
  --pgsql-db=STRING       PostgreSQL database name [sbtest]

Compiled-in tests:
  fileio - File I/O test
  cpu - CPU performance test
  memory - Memory functions speed test
  threads - Threads subsystem performance test
  mutex - Mutex performance test

See &#39;sysbench &lt;testname&gt; help&#39; for a list of options for each test.

$ ls -la /usr/share/sysbench/tests/include/oltp_legacy/
total 56
drwxr-xr-x 2 root root  284 Sep  7 20:53 .
drwxr-xr-x 3 root root 4096 Sep  7 20:53 ..
-rw-r--r-- 1 root root 1195 Apr 24  2020 bulk_insert.lua
-rw-r--r-- 1 root root 4696 Apr 24  2020 common.lua
-rw-r--r-- 1 root root  366 Apr 24  2020 delete.lua
-rw-r--r-- 1 root root 1171 Apr 24  2020 insert.lua
-rw-r--r-- 1 root root 3004 Apr 24  2020 oltp.lua
-rw-r--r-- 1 root root  368 Apr 24  2020 oltp_simple.lua
-rw-r--r-- 1 root root  527 Apr 24  2020 parallel_prepare.lua
-rw-r--r-- 1 root root  369 Apr 24  2020 select.lua
-rw-r--r-- 1 root root 1448 Apr 24  2020 select_random_points.lua
-rw-r--r-- 1 root root 1556 Apr 24  2020 select_random_ranges.lua
-rw-r--r-- 1 root root  369 Apr 24  2020 update_index.lua
-rw-r--r-- 1 root root  578 Apr 24  2020 update_non_index.lua
</code></pre>
<h2 id="MariaDB-vs-MySQL"><a href="#MariaDB-vs-MySQL" class="headerlink" title="MariaDB vs. MySQL"></a>MariaDB vs. MySQL</h2><p>MariaDB is a community-developed, commercially supported fork of the MySQL relational database management system (RDBMS), intended to remain free and open-source software under the GNU General Public License. Development is led by some of the original developers of MySQL, who forked it due to concerns over its acquisition by Oracle Corporation in 2009. Refer to <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/MariaDB">wiki</a> for more information.</p>
<h2 id="Create-the-MariaDB-database"><a href="#Create-the-MariaDB-database" class="headerlink" title="Create the MariaDB database"></a>Create the MariaDB database</h2><h3 id="Provision-the-MariaDB-docker-instance"><a href="#Provision-the-MariaDB-docker-instance" class="headerlink" title="Provision the MariaDB docker instance"></a>Provision the MariaDB docker instance</h3><p>In this example, we use Portworx to manage the disk storage. A volume <em>testVol</em> is created to store MariaDB data.</p>
<pre><code>$ pxctl v create testVol --size 1024 --repl 1

$ docker run --name mariadbtest -v testVol:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=password -p 3306:3306 -d docker.io/library/mariadb:latest

$ docker ps | egrep &quot;CONTAINER|mariadbtest&quot;
CONTAINER ID   IMAGE                        COMMAND                  CREATED          STATUS          PORTS                                       NAMES
2e5fe8ca177d   mariadb:latest               &quot;docker-entrypoint.s…&quot;   39 seconds ago   Up 37 seconds   0.0.0.0:3306-&gt;3306/tcp, :::3306-&gt;3306/tcp   mariadbtest
</code></pre>
<h3 id="Create-a-database"><a href="#Create-a-database" class="headerlink" title="Create a database"></a>Create a database</h3><pre><code>$ docker exec -it mariadbtest bash

root@2e5fe8ca177d:/# ip a | grep eth
139: eth0@if140: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default
    link/ether 02:42:ac:11:00:05 brd ff:ff:ff:ff:ff:ff link-netnsid 0
    inet 172.17.0.5/16 brd 172.17.255.255 scope global eth0

root@2e5fe8ca177d:/# df -h 
Filesystem                       Size  Used Avail Use% Mounted on
overlay                           50G   23G   28G  45% /
tmpfs                             64M     0   64M   0% /dev
tmpfs                            126G     0  126G   0% /sys/fs/cgroup
shm                               64M     0   64M   0% /dev/shm
/dev/mapper/centos-root           50G   23G   28G  45% /etc/hosts
/dev/pxd/pxd1020609855122786711 1007G  209M  956G   1% /var/lib/mysql
tmpfs                            126G     0  126G   0% /proc/acpi
tmpfs                            126G     0  126G   0% /proc/scsi
tmpfs                            126G     0  126G   0% /sys/firmware

root@2e5fe8ca177d:/# ls -la /var/lib/mysql
total 123332
drwxr-xr-x. 5 mysql mysql      4096 Sep  7 21:02 .
drwxr-xr-x  1 root  root         68 Aug 31 03:44 ..
-rw-rw----  1 mysql mysql    417792 Sep  7 21:02 aria_log.00000001
-rw-rw----  1 mysql mysql        52 Sep  7 21:02 aria_log_control
-rw-rw----  1 mysql mysql         9 Sep  7 21:02 ddl_recovery.log
-rw-rw----  1 mysql mysql       946 Sep  7 21:02 ib_buffer_pool
-rw-rw----  1 mysql mysql 100663296 Sep  7 21:02 ib_logfile0
-rw-rw----  1 mysql mysql  12582912 Sep  7 21:02 ibdata1
-rw-rw----  1 mysql mysql  12582912 Sep  7 21:02 ibtmp1
-rw-rw----  1 mysql mysql         0 Sep  7 21:00 multi-master.info
drwx------  2 mysql mysql      4096 Sep  7 21:00 mysql
drwx------  2 mysql mysql      4096 Sep  7 21:00 performance_schema
drwx------  2 mysql mysql     12288 Sep  7 21:00 sys

root@2e5fe8ca177d:/#  mysql -u root -p
Enter password:
Welcome to the MariaDB monitor.  Commands end with ; or \g.
Your MariaDB connection id is 3
Server version: 10.6.4-MariaDB-1:10.6.4+maria~focal mariadb.org binary distribution

Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.

Type &#39;help;&#39; or &#39;\h&#39; for help. Type &#39;\c&#39; to clear the current input statement.

MariaDB [(none)]&gt; SHOW VARIABLES LIKE &quot;%version%&quot;;
+-----------------------------------+------------------------------------------+
| Variable_name                     | Value                                    |
+-----------------------------------+------------------------------------------+
| in_predicate_conversion_threshold | 1000                                     |
| innodb_version                    | 10.6.4                                   |
| protocol_version                  | 10                                       |
| slave_type_conversions            |                                          |
| system_versioning_alter_history   | ERROR                                    |
| system_versioning_asof            | DEFAULT                                  |
| tls_version                       | TLSv1.1,TLSv1.2,TLSv1.3                  |
| version                           | 10.6.4-MariaDB-1:10.6.4+maria~focal      |
| version_comment                   | mariadb.org binary distribution          |
| version_compile_machine           | x86_64                                   |
| version_compile_os                | debian-linux-gnu                         |
| version_malloc_library            | system                                   |
| version_source_revision           | 2db692f5b4d6bb31a331dab44544171c455f6aca |
| version_ssl_library               | OpenSSL 1.1.1f  31 Mar 2020              |
| wsrep_patch_version               | wsrep_26.22                              |
+-----------------------------------+------------------------------------------+
15 rows in set (0.002 sec)

MariaDB [(none)]&gt; SHOW VARIABLES WHERE Variable_Name LIKE &quot;%dir&quot;;
+---------------------------+----------------------------+
| Variable_name             | Value                      |
+---------------------------+----------------------------+
| aria_sync_log_dir         | NEWFILE                    |
| basedir                   | /usr                       |
| character_sets_dir        | /usr/share/mysql/charsets/ |
| datadir                   | /var/lib/mysql/            |
| innodb_data_home_dir      |                            |
| innodb_log_group_home_dir | ./                         |
| innodb_tmpdir             |                            |
| lc_messages_dir           | /usr/share/mysql           |
| plugin_dir                | /usr/lib/mysql/plugin/     |
| slave_load_tmpdir         | /tmp                       |
| tmpdir                    | /tmp                       |
| wsrep_data_home_dir       | /var/lib/mysql/            |
+---------------------------+----------------------------+
12 rows in set (0.002 sec)

MariaDB [(none)]&gt; CREATE DATABASE sbtest;
Query OK, 1 row affected (0.001 sec)

MariaDB [(none)]&gt; CREATE USER sbtest@localhost;
Query OK, 0 rows affected (0.004 sec)

MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON sbtest.* TO sbtest@localhost;
Query OK, 0 rows affected (0.002 sec)

MariaDB [(none)]&gt; use sbtest;
Database changed

MariaDB [sbtest]&gt; select database();
+------------+
| database() |
+------------+
| sbtest     |
+------------+
1 row in set (0.000 sec)

MariaDB [sbtest]&gt; show tables;
Empty set (0.000 sec)

MariaDB [(none)]&gt;  exit
Bye
root@2e5fe8ca177d:/# exit
exit

root@2e5fe8ca177d:/# ls -la /var/lib/mysql
total 123336
drwxr-xr-x. 6 mysql mysql      4096 Sep  7 21:07 .
drwxr-xr-x  1 root  root         68 Aug 31 03:44 ..
-rw-rw----  1 mysql mysql    417792 Sep  7 21:07 aria_log.00000001
-rw-rw----  1 mysql mysql        52 Sep  7 21:02 aria_log_control
-rw-rw----  1 mysql mysql         9 Sep  7 21:02 ddl_recovery.log
-rw-rw----  1 mysql mysql       946 Sep  7 21:02 ib_buffer_pool
-rw-rw----  1 mysql mysql 100663296 Sep  7 21:02 ib_logfile0
-rw-rw----  1 mysql mysql  12582912 Sep  7 21:02 ibdata1
-rw-rw----  1 mysql mysql  12582912 Sep  7 21:02 ibtmp1
-rw-rw----  1 mysql mysql         0 Sep  7 21:00 multi-master.info
drwx------  2 mysql mysql      4096 Sep  7 21:00 mysql
drwx------  2 mysql mysql      4096 Sep  7 21:00 performance_schema
drwx------  2 mysql mysql      4096 Sep  7 21:07 sbtest
drwx------  2 mysql mysql     12288 Sep  7 21:00 sys
root@2e5fe8ca177d:/# ls -la /var/lib/mysql/sbtest/
total 12
drwx------  2 mysql mysql 4096 Sep  7 21:07 .
drwxr-xr-x. 6 mysql mysql 4096 Sep  7 21:07 ..
-rw-rw----  1 mysql mysql   67 Sep  7 21:07 db.opt
</code></pre>
<h3 id="Build-the-database"><a href="#Build-the-database" class="headerlink" title="Build the database"></a>Build the database</h3><p>On the host, using sysbench to create tables and insert data rows in the database. We need know how much data should be created in the database. 1 million rows will result in ~240MB of data. So, 32 tables, 2 millions rows each create 15GB data.</p>
<pre><code>$ sysbench /usr/share/sysbench/tests/include/oltp_legacy/oltp.lua --threads=1 --mysql-host=172.17.0.5 --mysql-password=password  --mysql-user=root --mysql-db=sbtest --oltp-tables-count=32 --oltp-table-size=2000000 prepare
sysbench 1.0.20 (using bundled LuaJIT 2.1.0-beta2)

Creating table &#39;sbtest1&#39;...
Inserting 2000000 records into &#39;sbtest1&#39;
Creating secondary indexes on &#39;sbtest1&#39;...
[omitted...]
</code></pre>
<p>In the MariaDB container, we can check the created data and table size.</p>
<pre><code>root@2e5fe8ca177d:/#  mysql -u root -p
MariaDB [sbtest]&gt; select * from sbtest1 limit 6;
+----+---------+-------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------+
| id | k       | c                                                                                                                       | pad                                                         |
+----+---------+-------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------+
|  1 |  998567 | 83868641912-28773972837-60736120486-75162659906-27563526494-20381887404-41576422241-93426793964-56405065102-33518432330 | 67847967377-48000963322-62604785301-91415491898-96926520291 |
|  2 | 1003937 | 38014276128-25250245652-62722561801-27818678124-24890218270-18312424692-92565570600-36243745486-21199862476-38576014630 | 23183251411-36241541236-31706421314-92007079971-60663066966 |
|  3 | 1008521 | 33973744704-80540844748-72700647445-87330233173-87249600839-07301471459-22846777364-58808996678-64607045326-48799346817 | 38615512647-91458489257-90681424432-95014675832-60408598704 |
|  4 | 1004027 | 37002370280-58842166667-00026392672-77506866252-09658311935-56926959306-83464667271-94685475868-28264244556-14550208498 | 63947013338-98809887124-59806726763-79831528812-45582457048 |
|  5 |  999625 | 44257470806-17967007152-32809666989-26174672567-29883439075-95767161284-94957565003-35708767253-53935174705-16168070783 | 34551750492-67990399350-81179284955-79299808058-21257255869 |
|  6 | 1001169 | 37216201353-39109531021-11197415756-87798784755-02463049870-83329763120-57551308766-61100580113-80090253566-30971527105 | 05161542529-00085727016-35134775864-52531204064-98744439797 |
+----+---------+-------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------+
6 rows in set (0.004 sec)

MariaDB [sbtest]&gt; SELECT   TABLE_NAME AS `Table`,   ROUND((DATA_LENGTH + INDEX_LENGTH) / 1024 / 1024) AS `Size (MB)` FROM   information_schema.TABLES WHERE   TABLE_SCHEMA = &quot;sbtest&quot; ORDER BY   (DATA_LENGTH + INDEX_LENGTH) DESC;
+---------+-----------+
| Table   | Size (MB) |
+---------+-----------+
| sbtest3 |       459 |
| sbtest1 |       459 |
| sbtest4 |       459 |
| sbtest2 |       459 |
| sbtest5 |       459 |
| sbtest6 |       146 |
+---------+-----------+
6 rows in set (0.002 sec)

MariaDB [sbtest]&gt; SELECT table_schema &quot;DB Name&quot;, ROUND(SUM(data_length + index_length) / 1024 / 1024, 1) &quot;DB Size in MB&quot;  FROM information_schema.tables  GROUP BY table_schema;
+--------------------+---------------+
| DB Name            | DB Size in MB |
+--------------------+---------------+
| information_schema |           0.2 |
| mysql              |          10.5 |
| performance_schema |           0.0 |
| sbtest             |       14702.0 |
| sys                |           0.0 |
+--------------------+---------------+
5 rows in set (0.033 sec)
</code></pre>
<p>We also can check the running process in the MariaDB.</p>
<pre><code>MariaDB [sbtest]&gt; show processlist;
+----+------+------------------+--------+---------+------+----------
| Id | User | Host             | db     | Command | Time | State    | Info                                                                                                 | Progress |
+----+------+------------------+--------+---------+------+----------
|  7 | root | 172.17.0.1:55000 | sbtest | Query   |    0 | Update   | INSERT INTO sbtest13(k, c, pad) VALUES(1185731, &#39;26498931212-26730519067-66264645428-09623019003-787&#39; |    0.000 |
| 11 | root | localhost        | sbtest | Query   |    0 | starting | show processlist                                                                                     |    0.000 |
+----+------+------------------+--------+---------+------+----------
2 rows in set (0.000 sec)
</code></pre>
<h2 id="Run-sysbench-benchmark"><a href="#Run-sysbench-benchmark" class="headerlink" title="Run sysbench benchmark"></a>Run sysbench benchmark</h2><pre><code>$ threads=1; seconds=1800; interval=60
$ sysbench /usr/share/sysbench/tests/include/oltp_legacy/oltp.lua --threads=$threads --mysql-host=172.17.0.5 --mysql-password=password  --mysql-user=root  --oltp-tables-count=32 --oltp-table-size=2000000 --events=0 --time=$seconds --report-interval=$interval --delete_inserts=10 --index_updates=10 --non_index_updates=10 --db-ps-mode=disable run

SQL statistics:
    queries performed:
        read:                            1315888
        write:                           375968
        other:                           187984
        total:                           1879840
    transactions:                        93992  (52.22 per sec.)
    queries:                             1879840 (1044.35 per sec.)
    ignored errors:                      0      (0.00 per sec.)
    reconnects:                          0      (0.00 per sec.)

General statistics:
    total time:                          1800.0066s
    total number of events:              93992

Latency (ms):
         min:                                    6.52
         avg:                                   19.14
         max:                                 1018.82
         95th percentile:                       25.28
         sum:                              1799473.52

Threads fairness:
    events (avg/stddev):           93992.0000/0.00
    execution time (avg/stddev):   1799.4735/0.00
</code></pre>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/MariaDB">https://en.wikipedia.org/wiki/MariaDB</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/akopytov/sysbench">https://github.com/akopytov/sysbench</a></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.flamingbytes.com/blog/an-easy-guide-to-install-kubernetes-cluster-with-kubeadm/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/logo/FlamingBytes-icon-64x64-1.png">
      <meta itemprop="name" content="relentlesstorm">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FlamingBytes">
      <meta itemprop="description" content="Stay hungry, stay foolish">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | FlamingBytes">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/blog/an-easy-guide-to-install-kubernetes-cluster-with-kubeadm/" class="post-title-link" itemprop="url">An easy guide to install kubernetes cluster with kubeadm</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-08-29 07:00:00" itemprop="dateCreated datePublished" datetime="2021-08-29T07:00:00-07:00">2021-08-29</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-10-22 11:28:20" itemprop="dateModified" datetime="2023-10-22T11:28:20-07:00">2023-10-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Tech/" itemprop="url" rel="index"><span itemprop="name">Tech</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Tech/Big-Data/" itemprop="url" rel="index"><span itemprop="name">Big Data</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>Kubernetes can be installed with the following deployments tools.</p>
<ul>
<li>Bootstrapping clusters with kubeadm</li>
<li>Installing Kubernetes with kops</li>
<li>Installing Kubernetes with Kubespray</li>
</ul>
<p>In this article, we learn to install Kubernetes cluster with kubeadm.</p>
<h2 id="Prepare-the-cluster-nodes"><a href="#Prepare-the-cluster-nodes" class="headerlink" title="Prepare the cluster nodes"></a>Prepare the cluster nodes</h2><p>We have three Centos nodes to install Kubernetes cluster.</p>
<pre><code>$ cat /etc/centos-release
CentOS Linux release 7.9.2009 (Core)
$ uname -r
3.10.0-1160.11.1.el7.x86_64
</code></pre>
<h2 id="Configuring-network-firewall-and-selinux"><a href="#Configuring-network-firewall-and-selinux" class="headerlink" title="Configuring network, firewall and selinux"></a>Configuring network, firewall and selinux</h2><p>We disable firewall and selinux to make deployment easier and this is only for study purpose.</p>
<p>You can configure network by following the <a target="_blank" rel="noopener" href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/">official document</a>.</p>
<h2 id="Installing-container-runtime"><a href="#Installing-container-runtime" class="headerlink" title="Installing container runtime"></a>Installing container runtime</h2><p>To run containers in Pods, Kubernetes uses a container runtime. We need to install a container runtime into each node in the cluster so that Pods can run there. The following are the common container runtimes with Kubernetes on Linux:</p>
<ul>
<li>containerd</li>
<li>CRI-O</li>
<li>Docker</li>
</ul>
<h3 id="Install-Docker-runtime"><a href="#Install-Docker-runtime" class="headerlink" title="Install Docker runtime"></a>Install Docker runtime</h3><p>On each node, install Docker Engine as below:</p>
<pre><code>$ yum install -y yum-utils
$ yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
$ yum install docker-ce docker-ce-cli containerd.io
$ systemctl start docker
$ systemctl status docker
</code></pre>
<h3 id="Configure-Docker-daemon"><a href="#Configure-Docker-daemon" class="headerlink" title="Configure Docker daemon"></a>Configure Docker daemon</h3><p>On each node, configure the Docker daemon, in particular to use systemd for the management of the container’s cgroups.</p>
<pre><code>$ sudo mkdir /etc/docker
$ cat &lt;&lt;EOF | sudo tee /etc/docker/daemon.json
&#123;
  &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;],
  &quot;log-driver&quot;: &quot;json-file&quot;,
  &quot;log-opts&quot;: &#123;
    &quot;max-size&quot;: &quot;100m&quot;
  &#125;,
  &quot;storage-driver&quot;: &quot;overlay2&quot;
&#125;
EOF

$ sudo systemctl enable docker
$ sudo systemctl daemon-reload
$ sudo systemctl restart docker
</code></pre>
<p><strong>Note</strong>: overlay2 is the preferred storage driver for systems running Linux kernel version 4.0 or higher, or RHEL or CentOS using version 3.10.0-514 and above.</p>
<h2 id="Installing-kubeadm-kubelet-and-kubectl"><a href="#Installing-kubeadm-kubelet-and-kubectl" class="headerlink" title="Installing kubeadm, kubelet and kubectl"></a>Installing kubeadm, kubelet and kubectl</h2><p>We need to install the following packages on all of cluster nodes:</p>
<ul>
<li><p>kubeadm: the command to bootstrap the cluster.</p>
</li>
<li><p>kubelet: the component that runs on all of the machines in the cluster and does things like starting pods and containers.</p>
</li>
<li><p>kubectl: the command line util to talk to the cluster.</p>
<p>  $ cat &lt;&lt;EOF | sudo tee &#x2F;etc&#x2F;yum.repos.d&#x2F;kubernetes.repo<br>  [kubernetes]<br>  name&#x3D;Kubernetes<br>  baseurl&#x3D;<a target="_blank" rel="noopener" href="https://packages.cloud.google.com/yum/repos/kubernetes-el7-/$basearch">https://packages.cloud.google.com/yum/repos/kubernetes-el7-\$basearch</a><br>  enabled&#x3D;1<br>  gpgcheck&#x3D;1<br>  repo_gpgcheck&#x3D;1<br>  gpgkey&#x3D;<a target="_blank" rel="noopener" href="https://packages.cloud.google.com/yum/doc/yum-key.gpg">https://packages.cloud.google.com/yum/doc/yum-key.gpg</a> <a target="_blank" rel="noopener" href="https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg">https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg</a><br>  exclude&#x3D;kubelet kubeadm kubectl<br>  EOF</p>
<p>  $ sudo yum install -y kubelet kubeadm kubectl –disableexcludes&#x3D;kubernetes<br>  Installed:<br>kubeadm.x86_64 0:1.22.1-0                      kubectl.x86_64 0:1.22.1-0                      kubelet.x86_64 0:1.22.1-0<br>  $ sudo systemctl enable –now kubelet</p>
</li>
</ul>
<h2 id="Configuring-a-cgroup-driver"><a href="#Configuring-a-cgroup-driver" class="headerlink" title="Configuring a cgroup driver"></a>Configuring a cgroup driver</h2><p>Both the container runtime and the kubelet have a property called “cgroup driver”, which is important for the management of cgroups on Linux machines.</p>
<p>kubeadm allows you to pass a KubeletConfiguration structure during kubeadm init. This KubeletConfiguration can include the cgroupDriver field which controls the cgroup driver of the kubelet.</p>
<p>A minimal example of configuring the field explicitly:</p>
<pre><code>[root@node1 ~]# cat kubeadm-config.yaml
kind: ClusterConfiguration
apiVersion: kubeadm.k8s.io/v1beta3
kubernetesVersion: v1.22.1
---
kind: KubeletConfiguration
apiVersion: kubelet.config.k8s.io/v1beta1
cgroupDriver: systemd
</code></pre>
<p>Such a configuration file can then be passed to the kubeadm command:</p>
<pre><code>[root@node1 ~]# kubeadm init --config kubeadm-config.yaml
[init] Using Kubernetes version: v1.22.1
[preflight] Running pre-flight checks
[preflight] Pulling images required for setting up a Kubernetes cluster
[preflight] This might take a minute or two, depending on the speed of your internet connection
[preflight] You can also perform this action in beforehand using &#39;kubeadm config images pull&#39;
[certs] Using certificateDir folder &quot;/etc/kubernetes/pki&quot;
[certs] Generating &quot;ca&quot; certificate and key
[certs] Generating &quot;apiserver&quot; certificate and key
[certs] apiserver serving cert is signed for DNS names [node1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 &lt;node1-ip&gt;]
[certs] Generating &quot;apiserver-kubelet-client&quot; certificate and key
[certs] Generating &quot;front-proxy-ca&quot; certificate and key
[certs] Generating &quot;front-proxy-client&quot; certificate and key
[certs] Generating &quot;etcd/ca&quot; certificate and key
[certs] Generating &quot;etcd/server&quot; certificate and key
[certs] etcd/server serving cert is signed for DNS names [node1 localhost] and IPs [&lt;node1-ip&gt; 127.0.0.1 ::1]
[certs] Generating &quot;etcd/peer&quot; certificate and key
[certs] etcd/peer serving cert is signed for DNS names [node1 localhost] and IPs [&lt;node1-ip&gt; 127.0.0.1 ::1]
[certs] Generating &quot;etcd/healthcheck-client&quot; certificate and key
[certs] Generating &quot;apiserver-etcd-client&quot; certificate and key
[certs] Generating &quot;sa&quot; key and public key
[kubeconfig] Using kubeconfig folder &quot;/etc/kubernetes&quot;
[kubeconfig] Writing &quot;admin.conf&quot; kubeconfig file
[kubeconfig] Writing &quot;kubelet.conf&quot; kubeconfig file
[kubeconfig] Writing &quot;controller-manager.conf&quot; kubeconfig file
[kubeconfig] Writing &quot;scheduler.conf&quot; kubeconfig file
[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;
[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;
[kubelet-start] Starting the kubelet
[control-plane] Using manifest folder &quot;/etc/kubernetes/manifests&quot;
[control-plane] Creating static Pod manifest for &quot;kube-apiserver&quot;
[control-plane] Creating static Pod manifest for &quot;kube-controller-manager&quot;
[control-plane] Creating static Pod manifest for &quot;kube-scheduler&quot;
[etcd] Creating static Pod manifest for local etcd in &quot;/etc/kubernetes/manifests&quot;
[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory &quot;/etc/kubernetes/manifests&quot;. This can take up to 4m0s
[apiclient] All control plane components are healthy after 9.002713 seconds
[upload-config] Storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace
[kubelet] Creating a ConfigMap &quot;kubelet-config-1.22&quot; in namespace kube-system with the configuration for the kubelets in the cluster
[upload-certs] Skipping phase. Please see --upload-certs
[mark-control-plane] Marking the node node1 as control-plane by adding the labels: [node-role.kubernetes.io/master(deprecated) node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]
[mark-control-plane] Marking the node node1 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]
[bootstrap-token] Using token: un7mhw.i9enhg84xl2tpgup
[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes
[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
[bootstrap-token] Creating the &quot;cluster-info&quot; ConfigMap in the &quot;kube-public&quot; namespace
[kubelet-finalize] Updating &quot;/etc/kubernetes/kubelet.conf&quot; to point to a rotatable kubelet client certificate and key
[addons] Applied essential addon: CoreDNS
[addons] Applied essential addon: kube-proxy

Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

Alternatively, if you are the root user, you can run:

  export KUBECONFIG=/etc/kubernetes/admin.conf

You should now deploy a pod network to the cluster.
Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join &lt;node1-ip&gt;:6443 --token un7mhw.i9enhg84xl2tpgup \
    --discovery-token-ca-cert-hash sha256:5553ba3acbbec95383fc4a274e4f21126ac8101c39dfe5262718a9f0fd1b3c32
</code></pre>
<h2 id="Creating-a-cluster-with-kubeadm"><a href="#Creating-a-cluster-with-kubeadm" class="headerlink" title="Creating a cluster with kubeadm"></a>Creating a cluster with kubeadm</h2><p>Using kubeadm, you can create a minimum viable Kubernetes cluster that conforms to best practices.</p>
<p>The kubeadm tool is good if you need:</p>
<ul>
<li>A simple way for you to try out Kubernetes, possibly for the first time.</li>
<li>A way for existing users to automate setting up a cluster and test their application.</li>
<li>A building block in other ecosystem and&#x2F;or installer tools with a larger scope.</li>
</ul>
<h3 id="Initializing-the-control-plane-node"><a href="#Initializing-the-control-plane-node" class="headerlink" title="Initializing the control-plane node"></a>Initializing the control-plane node</h3><p>The control-plane node is the machine where the control plane components run, including etcd (the cluster database) and the API Server (which the kubectl command line tool communicates with).</p>
<ol>
<li>(Recommended) If you have plans to upgrade this single control-plane kubeadm cluster to high availability you should specify the –control-plane-endpoint to set the shared endpoint for all control-plane nodes. Such an endpoint can be either a DNS name or an IP address of a load-balancer.</li>
<li>Choose a Pod network add-on, and verify whether it requires any arguments to be passed to kubeadm init. Depending on which third-party provider you choose, you might need to set the –pod-network-cidr to a provider-specific value.</li>
<li>(Optional) Since version 1.14, kubeadm tries to detect the container runtime on Linux by using a list of well known domain socket paths. To use different container runtime or if there are more than one installed on the provisioned node, specify the –cri-socket argument to kubeadm init.</li>
<li>(Optional) Unless otherwise specified, kubeadm uses the network interface associated with the default gateway to set the advertise address for this particular control-plane node’s API server. To use a different network interface, specify the –apiserver-advertise-address&#x3D; argument to kubeadm init. To deploy an IPv6 Kubernetes cluster using IPv6 addressing, you must specify an IPv6 address, for example –apiserver-advertise-address&#x3D;fd00::101</li>
<li>(Optional) Run kubeadm config images pull prior to kubeadm init to verify connectivity to the gcr.io container image registry</li>
</ol>
<p>To initialize the control-plane node run “kubeadm init “.</p>
<pre><code>$ kubeadm init --pod-network-cidr=192.168.0.0/16 
</code></pre>
<p><strong>kubeadm init</strong> first runs a series of prechecks to ensure that the machine is ready to run Kubernetes. These prechecks expose warnings and exit on errors. kubeadm init then downloads and installs the cluster control plane components. This may take several minutes.</p>
<p>In previous section <strong>Configuring a cgroup driver</strong>, we have run the command to initialize the control-plane node.</p>
<p>If you need to run kubeadm init again, you must first <a target="_blank" rel="noopener" href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#tear-down">tear down the cluster</a>.</p>
<pre><code>[root@node1 ~]# kubeadm reset
</code></pre>
<p>Execute the following commands to configure kubectl (also returned by kubeadm init) if you are the root user.</p>
<pre><code>[root@node1 ~]# export KUBECONFIG=/etc/kubernetes/admin.conf
</code></pre>
<h2 id="Installing-a-Pod-network-add-on"><a href="#Installing-a-Pod-network-add-on" class="headerlink" title="Installing a Pod network add-on"></a>Installing a Pod network add-on</h2><p>In this practice, we install <a target="_blank" rel="noopener" href="https://docs.projectcalico.org/getting-started/kubernetes/quickstart">Calico</a> which is an open source networking and network security solution for containers, virtual machines, and native host-based workloads.</p>
<pre><code>[root@node1 ~]# kubectl create -f https://docs.projectcalico.org/manifests/tigera-operator.yaml
[root@node1 ~]# kubectl create -f https://docs.projectcalico.org/manifests/custom-resources.yaml

Note: Before creating this manifest, read its contents and make sure its settings are correct for your environment. For example, you may need to change the default IP pool CIDR to match your pod network CIDR.

[root@node1 ~]# kubectl get nodes
NAME                                 STATUS   ROLES                  AGE   VERSION
node1   Ready    control-plane,master   11m   v1.22.1

[root@node1 ~]# kubectl get pods -n calico-system
NAME                                       READY   STATUS    RESTARTS   AGE
calico-kube-controllers-868b656ff4-gv2tq   1/1     Running   0          2m41s
calico-node-wclb2                          1/1     Running   0          2m41s
calico-typha-d8c5c85c5-kldfh               1/1     Running   0          2m42s

[root@node1 ~]# kubectl get pods --all-namespaces
NAMESPACE          NAME                                        READY   STATUS    RESTARTS   AGE
calico-apiserver   calico-apiserver-554fbf9554-45d6l           1/1     Running   0          15m
calico-system      calico-kube-controllers-868b656ff4-gv2tq    1/1     Running   0          16m
calico-system      calico-node-wclb2                           1/1     Running   0          16m
calico-system      calico-typha-d8c5c85c5-kldfh                1/1     Running   0          16m
kube-system        coredns-78fcd69978-lq9pp                    1/1     Running   0          18m
kube-system        coredns-78fcd69978-nm29f                    1/1     Running   0          18m
kube-system        etcd-node1                                  1/1     Running   1          19m
kube-system        kube-apiserver-node1                        1/1     Running   1          19m
kube-system        kube-controller-manager-node1               1/1     Running   0          19m
kube-system        kube-proxy-m48qn                            1/1     Running   0          18m
kube-system        kube-scheduler-node1                        1/1     Running   1          19m
tigera-operator    tigera-operator-698876cbb5-dghgv            1/1     Running   0          17m
</code></pre>
<p>You can install only one Pod network per cluster.</p>
<h2 id="Control-plane-node-isolation"><a href="#Control-plane-node-isolation" class="headerlink" title="Control plane node isolation"></a>Control plane node isolation</h2><p>Untaint the master so that it will be available for scheduling workloads</p>
<pre><code>[root@node1 ~]# kubectl taint nodes --all node-role.kubernetes.io/master-
node/node1 untainted
</code></pre>
<h2 id="Joining-your-nodes"><a href="#Joining-your-nodes" class="headerlink" title="Joining your nodes"></a>Joining your nodes</h2><p>The nodes are where your workloads (containers and Pods, etc) run. To add new nodes to your cluster do the following for each machine:</p>
<ul>
<li><p>SSH to the machine</p>
</li>
<li><p>Become root (e.g. sudo su -)</p>
</li>
<li><p>Run the command that was output by kubeadm init</p>
<p>  [root@node2 ~]# kubeadm join <node1-ip>:6443 –token un7mhw.i9enhg84xl2tpgup –discovery-token-ca-cert-hash sha256:5553ba3acbbec95383fc4a274e4f21126ac8101c39dfe5262718a9f0fd1b3c32<br>  [root@node3 ~]# kubeadm join <node1-ip>:6443 –token un7mhw.i9enhg84xl2tpgup –discovery-token-ca-cert-hash sha256:5553ba3acbbec95383fc4a274e4f21126ac8101c39dfe5262718a9f0fd1b3c32<br>  [preflight] Running pre-flight checks<br>  [preflight] Reading configuration from the cluster…<br>  [preflight] FYI: You can look at this config file with ‘kubectl -n kube-system get cm kubeadm-config -o yaml’<br>  [kubelet-start] Writing kubelet configuration to file “&#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;config.yaml”<br>  [kubelet-start] Writing kubelet environment file with flags to file “&#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;kubeadm-flags.env”<br>  [kubelet-start] Starting the kubelet<br>  [kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap…</p>
<p>  This node has joined the cluster:</p>
<ul>
<li>Certificate signing request was sent to apiserver and a response was received.</li>
<li>The Kubelet was informed of the new secure connection details.</li>
</ul>
<p>  Run ‘kubectl get nodes’ on the control-plane to see this node join the cluster.</p>
</li>
</ul>
<p>If you do not have the token, you can get it by running the following command on the control-plane node:</p>
<pre><code>$ kubeadm token list
</code></pre>
<p>By default, tokens expire after 24 hours. If you are joining a node to the cluster after the current token has expired, you can create a new token by running the following command on the control-plane node:</p>
<pre><code>$ kubeadm token create
</code></pre>
<p>If you don’t have the value of –discovery-token-ca-cert-hash, you can get it by running the following command chain on the control-plane node:</p>
<pre><code>$ openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null | openssl dgst -sha256 -hex | sed &#39;s/^.* //&#39; 
</code></pre>
<p>We can check the cluster nodes as below.</p>
<pre><code>[root@node1 ~]#  kubectl get nodes
NAME    STATUS   ROLES                  AGE     VERSION
node1   Ready    control-plane,master   37m     v1.22.1
node2   Ready    &lt;none&gt;                 4m56s   v1.22.1
node3   Ready    &lt;none&gt;                 7m49s   v1.22.1

[root@node1 ~]# kubectl get pods --all-namespaces
NAMESPACE          NAME                                        READY   STATUS    RESTARTS   AGE
calico-apiserver   calico-apiserver-554fbf9554-45d6l           1/1     Running   0          34m
calico-system      calico-kube-controllers-868b656ff4-gv2tq    1/1     Running   0          35m
calico-system      calico-node-cl5kt                           1/1     Running   0          7m51s
calico-system      calico-node-rtgcs                           1/1     Running   0          4m58s
calico-system      calico-node-wclb2                           1/1     Running   0          35m
calico-system      calico-typha-d8c5c85c5-7knvv                1/1     Running   0          7m46s
calico-system      calico-typha-d8c5c85c5-kldfh                1/1     Running   0          35m
calico-system      calico-typha-d8c5c85c5-qflvv                1/1     Running   0          4m56s
kube-system        coredns-78fcd69978-lq9pp                    1/1     Running   0          37m
kube-system        coredns-78fcd69978-nm29f                    1/1     Running   0          37m
kube-system        etcd-node1                                  1/1     Running   1          37m
kube-system        kube-apiserver-node1                        1/1     Running   1          37m
kube-system        kube-controller-manager-node1               1/1     Running   0          37m
kube-system        kube-proxy-d55xr                            1/1     Running   0          7m51s
kube-system        kube-proxy-m48qn                            1/1     Running   0          37m
kube-system        kube-proxy-m7drg                            1/1     Running   0          4m58s
kube-system        kube-scheduler-node1                        1/1     Running   1          37m
tigera-operator    tigera-operator-698876cbb5-dghgv            1/1     Running   0          35m
</code></pre>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a target="_blank" rel="noopener" href="https://kubernetes.io/docs/setup/production-environment/tools/">https://kubernetes.io/docs/setup/production-environment/tools/</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.projectcalico.org/about/about-calico">https://docs.projectcalico.org/about/about-calico</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.projectcalico.org/getting-started/kubernetes/quickstart">https://docs.projectcalico.org/getting-started/kubernetes/quickstart</a></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.flamingbytes.com/blog/vdbench-performance-test-on-filesystem/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/logo/FlamingBytes-icon-64x64-1.png">
      <meta itemprop="name" content="relentlesstorm">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FlamingBytes">
      <meta itemprop="description" content="Stay hungry, stay foolish">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | FlamingBytes">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/blog/vdbench-performance-test-on-filesystem/" class="post-title-link" itemprop="url">Vdbench performance test on filesystem</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-08-24 07:00:00" itemprop="dateCreated datePublished" datetime="2021-08-24T07:00:00-07:00">2021-08-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-10-22 11:28:20" itemprop="dateModified" datetime="2023-10-22T11:28:20-07:00">2023-10-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Tech/" itemprop="url" rel="index"><span itemprop="name">Tech</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Tech/Benchmarking/" itemprop="url" rel="index"><span itemprop="name">Benchmarking</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="File-system-testing-Method-1"><a href="#File-system-testing-Method-1" class="headerlink" title="File system testing - Method 1"></a>File system testing - Method 1</h2><p><strong>Vdbench filesystem testing terminologies:</strong></p>
<ul>
<li>Anchor - A directory or a filesystme mount point. A file system structure will be created by specifying the structure information including directory depth, width, number of files and file size. Multiple anchor can be defined and used by filesystem workloads.</li>
<li>Operation - File system operations. For example, directory create&#x2F;delete, file create&#x2F;delete, file read&#x2F;write, file open&#x2F;close, setattr and getattr.</li>
</ul>
<p><strong>Vdbench parameters for filesystem benchmark:</strong></p>
<ul>
<li>File system definition(FSD) - Describe the directory structure.</li>
<li>File system workload definition(FWD) - Describe the workload parameters.</li>
<li>Run definition(RD) - Describe how the workload will be run.</li>
</ul>
<p><strong>The following is an example of the vdbench job file.</strong></p>
<pre><code>hd=default,vdbench=/home/tester/vdbench_test,shell=ssh,user=root
hd=host1,jvms=1,system=192.168.1.50
fsd=fsd1,anchor=/mnt/testdir1,depth=1,width=1,files=4,size=50g,openflag=o_direct
fsd=fsd2,anchor=/mnt/testdir2,depth=1,width=1,files=4,size=50g,openflag=o_direct
fwd=fwd1,fsd=fsd1,host=host1,fileio=random,operation=write,xfersize=4k,fileselect=random,threads=$th
fwd=fwd2,fsd=fsd2,host=host1,fileio=random,operation=write,xfersize=4k,fileselect=random,threads=$th
rd=rd1,fwd=fwd*,fwdrate=max,format=yes,elapsed=180,interval=30
</code></pre>
<p>Explanation:</p>
<ol>
<li><p>hd - it specifies which host to run the filesystem workload. The number of jvms is default to 1. It can be increased if the number of jvms can not handle very high iops with a fast system.</p>
</li>
<li><p>fsd - it specifies under which directory to create the filesystem structures. “depth” defines how many level of directories will be created. “width” defines how many sub-directories will be created under each parent directory. “files” defines how many files will be created under each directory. “size” defines the file size. “openflag” controls how the file will be opened.</p>
</li>
<li><p>fwd - it specifies what workload will be run on the target filesystems. In this example, it will run random write with 4k blocksize. The specified number of threads will be used to write corresponding number of files. The files will be randomly selected for the workload to run. Note that, the number of threads should less than or equal to the number of files. Note that, the writes to the file is single threaded unless “filiio&#x3D;(random,shared) is specified.</p>
</li>
<li><p>rd - it controls how the workload will be run. In this example, the workload will be run for 3 minutes. The “format” option is very useful. It will recreate the filesystem structure before the workload run. It will give us more repeatable results. “fwdrate” indicates the iorate will be unlimited in order to stress the system as much as possible.</p>
</li>
<li><p>In this example, we run the 4k random write workload concurrently on two filesystems. The number of threads to write each filesystem can be controlled by passing from shell variable during run time as below.</p>
<p> .&#x2F;vdbench jobfile&#x2F;vdb.job th&#x3D;2</p>
</li>
</ol>
<h2 id="File-system-testing-Method-2"><a href="#File-system-testing-Method-2" class="headerlink" title="File system testing - Method 2"></a>File system testing - Method 2</h2><p>The similar workload in the method one can also be run as below.</p>
<pre><code>hd=default,vdbench=/home/tester/vdbench_test,shell=ssh,user=root
hd=host1,system=192.168.1.50
sd=sd1,host=host1,lun=/mnt/testdir1/testfile,hitarea=1m,openflag=o_direct,size=50g
sd=sd2,host=host1,lun=/mnt/testdir2/testfile,hitarea=1m,openflag=o_direct,size=50g
wd=wd1,sd=sd*,seekpct=100
rd=rd1,wd=wd1,iorate=max,rdpct=0,xfersize=4K,elapsed=180,interval=30,th=$th
</code></pre>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a target="_blank" rel="noopener" href="https://www.oracle.com/technetwork/server-storage/vdbench-1901683.pdf">https://www.oracle.com/technetwork/server-storage/vdbench-1901683.pdf</a></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.flamingbytes.com/blog/vdbench-performance-test-on-raw-device/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/logo/FlamingBytes-icon-64x64-1.png">
      <meta itemprop="name" content="relentlesstorm">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FlamingBytes">
      <meta itemprop="description" content="Stay hungry, stay foolish">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | FlamingBytes">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/blog/vdbench-performance-test-on-raw-device/" class="post-title-link" itemprop="url">Vdbench performance test on raw device</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-08-23 07:00:00" itemprop="dateCreated datePublished" datetime="2021-08-23T07:00:00-07:00">2021-08-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-10-22 11:28:20" itemprop="dateModified" datetime="2023-10-22T11:28:20-07:00">2023-10-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Tech/" itemprop="url" rel="index"><span itemprop="name">Tech</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Tech/Benchmarking/" itemprop="url" rel="index"><span itemprop="name">Benchmarking</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="Terminology"><a href="#Terminology" class="headerlink" title="Terminology"></a>Terminology</h2><ul>
<li><p><strong>Master and Slave</strong>: Vdbench runs as two or more Java Virtual Machines (JVMs). The JVM that you start is the master. The master takes care of the parsing of all the parameters, it determines which workloads should run, and then will also do all the reporting. The actual workload is executed by one or more Slaves. A Slave can run on the host where the Master was started, or it can run on any remote host as defined in the parameter file.</p>
</li>
<li><p><strong>Raw I&#x2F;O workload</strong> parameters describe the storage configuration to be used and the workload to be generated. The parameters include <strong>General</strong>, <strong>Host Definition (HD)</strong>, <strong>Replay Group (RG)</strong>, <strong>Storage Definition (SD)</strong>, <strong>Workload Definition (WD)</strong> and <strong>Run Definition (RD)</strong> and must always be entered in the order in which they are listed here. A <strong>Run</strong> is the execution of one workload requested by a <strong>Run Definition</strong>. Multiple Runs can be requested within one Run Definition.</p>
</li>
<li><p><strong>File system Workload</strong> parameters describe the file system configuration to be used and the workload to be generated. The parameters include <strong>General</strong>, <strong>Host Definition (HD)</strong>, <strong>File System Definition (FSD)</strong>, <strong>File system Workload Definition (FWD)</strong> and <strong>Run Definition(RD)</strong> and must always be entered in the order in which they are listed here. A <strong>Run</strong> is the execution of one workload requested by a <strong>Run Definition</strong>. Multiple Runs can be requested within one Run Definition.</p>
</li>
</ul>
<h2 id="Install-java"><a href="#Install-java" class="headerlink" title="Install java"></a>Install java</h2><p>java is required by vdbench on both master and slave hosts.</p>
<pre><code>$ apt install default-jre

$ java -version
openjdk version &quot;11.0.11&quot; 2021-04-20
OpenJDK Runtime Environment (build 11.0.11+9-Ubuntu-0ubuntu2.18.04)
OpenJDK 64-Bit Server VM (build 11.0.11+9-Ubuntu-0ubuntu2.18.04, mixed mode, sharing)
</code></pre>
<h2 id="Install-vdbench"><a href="#Install-vdbench" class="headerlink" title="Install vdbench"></a>Install vdbench</h2><p>Vdbench is packaged as a zip file. Unzip the file and you’re ready to go.</p>
<pre><code>$ ls -la vdbench50407.zip
-rw-r--r--. 1 root root 3073219 Aug 26 21:23 vdbench50407.zip

$ unzip vdbench50407.zip

$ file vdbench
vdbench: Bourne-Again shell script, ASCII text executable
</code></pre>
<h2 id="Vdbench-job-file"><a href="#Vdbench-job-file" class="headerlink" title="Vdbench job file"></a>Vdbench job file</h2><p>The following is an example job file to run random read I&#x2F;O for a minute on the raw block device of the remote host.</p>
<pre><code>$ cat jobfile/dryrun.job
hd=default,vdbench=/home/tester/vdbench,shell=ssh,user=root
hd=host1,system=&lt;slave-host-ip&gt;
sd=sd1,host=host1,lun=/dev/sdd,hitarea=10m,openflag=o_direct,size=20000m
wd=wd_random_rd1,sd=sd1,seekpct=100

# 4KB random read
rd=rd_4KB_randread,wd=wd_random_rd1,iorate=max,rdpct=100,xfersize=4K,elapsed=60,interval=10,th=1
</code></pre>
<h2 id="Benchmark-run-and-result"><a href="#Benchmark-run-and-result" class="headerlink" title="Benchmark run and result"></a>Benchmark run and result</h2><p>You can run the benchmark job with the following command.</p>
<pre><code>$ ./vdbench -f jobfile/dryrun.job
Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.
Vdbench distribution: vdbench50407 Tue June 05  9:49:29 MDT 2018
For documentation, see &#39;vdbench.pdf&#39;.

22:06:52.177 input argument scanned: &#39;-fjobfile/dryrun.job&#39;
22:06:52.353 Starting slave: ssh &lt;slave-host-ip&gt; -l root /home/tester/vdbench/vdbench SlaveJvm -m &lt;master-host-ip&gt; -n &lt;slave-host-ip&gt;-10-210826-22.06.52.140 -l host1-0 -p 5570
22:06:53.123 Clock synchronization warning: slave host1-0 is 41 seconds out of sync. This can lead to heartbeat issues.
22:06:53.140 All slaves are now connected
22:06:54.002 Starting RD=rd_4KB_randread; I/O rate: Uncontrolled MAX; elapsed=60; For loops: rdpct=100 xfersize=4k threads=1

Aug 26, 2021    interval        i/o   MB/sec   bytes   read     resp     read    write     read    write     resp  queue  cpu%  cpu%
                               rate  1024**2     i/o    pct     time     resp     resp      max      max   stddev  depth sys+u   sys
22:07:04.055           1     5563.1    21.73    4096 100.00    0.157    0.157    0.000    10.89     0.00    0.342    0.9  16.5   7.6
22:07:14.011           2     7022.2    27.43    4096 100.00    0.127    0.127    0.000     7.54     0.00    0.108    0.9  10.7   7.5
22:07:24.009           3     7018.5    27.42    4096 100.00    0.128    0.128    0.000     9.67     0.00    0.087    0.9  10.9   8.2
22:07:34.009           4     7026.8    27.45    4096 100.00    0.127    0.127    0.000     6.99     0.00    0.105    0.9  10.7   7.9
22:07:44.008           5     7264.4    28.38    4096 100.00    0.123    0.123    0.000     7.75     0.00    0.082    0.9  10.7   7.7
22:07:54.014           6     7311.4    28.56    4096 100.00    0.122    0.122    0.000     7.21     0.00    0.076    0.9  10.5   7.4
22:07:54.024     avg_2-6     7128.7    27.85    4096 100.00    0.126    0.126    0.000     9.67     0.00    0.092    0.9  10.7   7.7
22:07:54.445 Vdbench execution completed successfully. Output directory: /data/vdbench_test/output
</code></pre>
<p>The result is saved in output directory by default. You can also check the result summary by opening “summary.html” in a browser.</p>
<pre><code>$ ls output/
config.html    flatfile.html   host1-0.html         host1.html               logfile.html   parmscan.html       sd1.html   status.html   swat_mon_total.txt  totals.html errorlog.html  histogram.html  host1-0.stdout.html  host1.var_adm_msgs.html  parmfile.html  sd1.histogram.html  skew.html  summary.html  swat_mon.txt

$ cat output/summary.html
&lt;title&gt;Vdbench output/summary.html&lt;/title&gt;&lt;pre&gt;
Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.
Vdbench summary report, created 22:06:52 Aug 26 2021 UTC (22:06:52 Aug 26 2021 UTC)

Link to logfile:                 &lt;A HREF=&quot;logfile.html&quot;&gt;logfile&lt;/A&gt;
Run totals:                      &lt;A HREF=&quot;totals.html&quot;&gt;totals&lt;/A&gt;
Vdbench status:                  &lt;A HREF=&quot;status.html&quot;&gt;status&lt;/A&gt;
Copy of input parameter files:   &lt;A HREF=&quot;parmfile.html&quot;&gt;parmfile&lt;/A&gt;
Copy of parameter scan detail:   &lt;A HREF=&quot;parmscan.html&quot;&gt;parmscan&lt;/A&gt;
Link to errorlog:                &lt;A HREF=&quot;errorlog.html&quot;&gt;errorlog&lt;/A&gt;
Link to flatfile:                &lt;A HREF=&quot;flatfile.html&quot;&gt;flatfile&lt;/A&gt;

Link to HOST reports:            &lt;A HREF=&quot;host1.html&quot;&gt;host1&lt;/A&gt;
Link to response time histogram: &lt;A HREF=&quot;histogram.html&quot;&gt;histogram&lt;/A&gt;
Link to workload skew report:    &lt;A HREF=&quot;skew.html&quot;&gt;skew&lt;/A&gt;
Link to SD reports:              &lt;A HREF=&quot;sd1.html&quot;&gt;sd1&lt;/A&gt;

Link to Run Definitions:         &lt;A HREF=&quot;#_463345942&quot;&gt;rd_4KB_randread For loops: rdpct=100 xfersize=4k threads=1&lt;/A&gt;

Link to config output:           &lt;A HREF=&quot;config.html&quot;&gt;config&lt;/A&gt;

&lt;a name=&quot;_463345942&quot;&gt;&lt;/a&gt;&lt;i&gt;&lt;b&gt;22:06:54.002 Starting RD=rd_4KB_randread; I/O rate: Uncontrolled MAX; elapsed=60; For loops: rdpct=100 xfersize=4k threads=1&lt;/b&gt;&lt;/i&gt;


Aug 26, 2021    interval        i/o   MB/sec   bytes   read     resp     read    write     read    write     resp  queue  cpu%  cpu%
                               rate  1024**2     i/o    pct     time     resp     resp      max      max   stddev  depth sys+u   sys
22:07:04.052           1     5563.1    21.73    4096 100.00    0.157    0.157    0.000    10.89     0.00    0.342    0.9  16.5   7.6
22:07:14.010           2     7022.2    27.43    4096 100.00    0.127    0.127    0.000     7.54     0.00    0.108    0.9  10.7   7.5
22:07:24.008           3     7018.5    27.42    4096 100.00    0.128    0.128    0.000     9.67     0.00    0.087    0.9  10.9   8.2
22:07:34.008           4     7026.8    27.45    4096 100.00    0.127    0.127    0.000     6.99     0.00    0.105    0.9  10.7   7.9
22:07:44.008           5     7264.4    28.38    4096 100.00    0.123    0.123    0.000     7.75     0.00    0.082    0.9  10.7   7.7
22:07:54.014           6     7311.4    28.56    4096 100.00    0.122    0.122    0.000     7.21     0.00    0.076    0.9  10.5   7.4
22:07:54.023     avg_2-6     7128.7    27.85    4096 100.00    0.126    0.126    0.000     9.67     0.00    0.092    0.9  10.7   7.7
22:07:54.445 Vdbench execution completed successfully
</code></pre>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a target="_blank" rel="noopener" href="https://ubuntu.com/tutorials/install-jre#2-installing-openjdk-jre">https://ubuntu.com/tutorials/install-jre#2-installing-openjdk-jre</a></li>
<li><a target="_blank" rel="noopener" href="https://www.oracle.com/technetwork/server-storage/vdbench-1901683.pdf">https://www.oracle.com/technetwork/server-storage/vdbench-1901683.pdf</a></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.flamingbytes.com/blog/deploy-ceph-cluster-on-ubuntu-18-04-and-centos-7-8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/logo/FlamingBytes-icon-64x64-1.png">
      <meta itemprop="name" content="relentlesstorm">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FlamingBytes">
      <meta itemprop="description" content="Stay hungry, stay foolish">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | FlamingBytes">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/blog/deploy-ceph-cluster-on-ubuntu-18-04-and-centos-7-8/" class="post-title-link" itemprop="url">Deploy ceph cluster on Ubuntu 18.04 and CentOS 7.8</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-08-22 07:00:00" itemprop="dateCreated datePublished" datetime="2021-08-22T07:00:00-07:00">2021-08-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-10-22 11:28:20" itemprop="dateModified" datetime="2023-10-22T11:28:20-07:00">2023-10-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Tech/" itemprop="url" rel="index"><span itemprop="name">Tech</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Tech/Cloud-Storage/" itemprop="url" rel="index"><span itemprop="name">Cloud Storage</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>In this article, we learn to deploy ceph cluster on ubuntu 18.04. Three nodes are used for this study.</p>
<p>We target to deploy the most recent ceph release which is called <strong>Pacific</strong>. With this release, we can use <strong>cephadm</strong> to create a ceph cluster by <strong>bootstrapping</strong> on a single host and expanding the cluster to additional hosts.</p>
<h2 id="Intro-to-ceph"><a href="#Intro-to-ceph" class="headerlink" title="Intro to ceph"></a>Intro to ceph</h2><p>Whether you want to provide Ceph Object Storage and&#x2F;or Ceph Block Device services to Cloud Platforms, deploy a Ceph Filesystem or use Ceph for another purpose, all Ceph Storage Cluster deployments begin with setting up each Ceph Node, your network, and the Ceph Storage Cluster. A Ceph Storage Cluster requires at least one Ceph Monitor, Ceph Manager, and Ceph OSD (Object Storage Daemon). The Ceph Metadata Server is also required when running Ceph Filesystem clients.</p>
<ul>
<li><p><strong>Monitors</strong>: A Ceph Monitor (ceph-mon) maintains maps of the cluster state, including the monitor map, manager map, the OSD map, and the CRUSH map. These maps are critical cluster state required for Ceph daemons to coordinate with each other. Monitors are also responsible for managing authentication between daemons and clients. At least three monitors are normally required for redundancy and high availability.</p>
</li>
<li><p><strong>Managers</strong>: A Ceph Manager daemon (ceph-mgr) is responsible for keeping track of runtime metrics and the current state of the Ceph cluster, including storage utilization, current performance metrics, and system load. The Ceph Manager daemons also host python-based plugins to manage and expose Ceph cluster information, including a web-based dashboard and REST API. At least two managers are normally required for high availability.</p>
</li>
<li><p><strong>Ceph OSDs</strong>: A Ceph OSD (object storage daemon, ceph-osd) stores data, handles data replication, recovery, rebalancing, and provides some monitoring information to Ceph Monitors and Managers by checking other Ceph OSD Daemons for a heartbeat. At least 3 Ceph OSDs are normally required for redundancy and high availability.</p>
</li>
<li><p><strong>MDSs</strong>: A Ceph Metadata Server (MDS, ceph-mds) stores metadata on behalf of the Ceph Filesystem (i.e., Ceph Block Devices and Ceph Object Storage do not use MDS). Ceph Metadata Servers allow POSIX file system users to execute basic commands (like ls, find, etc.) without placing an enormous burden on the Ceph Storage Cluster.</p>
</li>
</ul>
<p>Ceph stores data as objects within logical storage pools. Using the CRUSH algorithm, Ceph calculates which placement group should contain the object, and further calculates which Ceph OSD Daemon should store the placement group. The CRUSH algorithm enables the Ceph Storage Cluster to scale, rebalance, and recover dynamically.</p>
<h2 id="Deploy-a-ceph-storage-cluster"><a href="#Deploy-a-ceph-storage-cluster" class="headerlink" title="Deploy a ceph storage cluster"></a>Deploy a ceph storage cluster</h2><h3 id="Prepare-Ubuntu-Linux-and-packages"><a href="#Prepare-Ubuntu-Linux-and-packages" class="headerlink" title="Prepare Ubuntu Linux and packages"></a>Prepare Ubuntu Linux and packages</h3><p>From ceph installation guide, the following system requirements must be met before deployment.</p>
<ul>
<li><p>Python 3</p>
</li>
<li><p>Systemd</p>
</li>
<li><p>Podman or Docker for running containers</p>
</li>
<li><p>Time synchronization (such as chrony or NTP)</p>
</li>
<li><p>LVM2 for provisioning storage devices</p>
<p>  root@host1:~# cat &#x2F;etc&#x2F;*release<br>  DISTRIB_ID&#x3D;Ubuntu<br>  DISTRIB_RELEASE&#x3D;16.04</p>
</li>
</ul>
<p><strong>Upgrade to Ubuntu 18.0.4</strong></p>
<pre><code>root@host1:~# apt install update-manager-core

root@host1:~# do-release-upgrade -c
Checking for a new Ubuntu release
New release &#39;18.04.5 LTS&#39; available.
Run &#39;do-release-upgrade&#39; to upgrade to it.

root@host1:~# do-release-upgrade

root@host1:~# cat /etc/*release
DISTRIB_ID=Ubuntu
DISTRIB_RELEASE=18.04
</code></pre>
<p><strong>Install python3</strong></p>
<pre><code>root@host1:~# apt-get install python3
</code></pre>
<p><strong>Install docker</strong></p>
<p>Refer to <a target="_blank" rel="noopener" href="https://docs.docker.com/engine/install/ubuntu/">here</a></p>
<p><strong>Install ntp</strong></p>
<pre><code>root@host1:~# apt-get install ntp
root@host1:~# service ntp start
root@host1:~# timedatectl set-timezone UTC
</code></pre>
<p><strong>Install lvm2</strong></p>
<pre><code>root@host1:~# apt-get install lvm2
</code></pre>
<p><strong>Check and disable firewall status</strong></p>
<pre><code>root@host1:~# ufw status
</code></pre>
<p><strong>Add cluster nodes to &#x2F;etc&#x2F;hosts</strong></p>
<p><strong>Configure passwordless ssh from primary host to the others</strong></p>
<h2 id="Install-cephadm"><a href="#Install-cephadm" class="headerlink" title="Install cephadm"></a>Install cephadm</h2><p>The cephadm command can</p>
<ul>
<li><p>bootstrap a new cluster</p>
</li>
<li><p>launch a containerized shell with a working Ceph CLI</p>
</li>
<li><p>aid in debugging containerized Ceph daemons</p>
<p>  root@host1:<del># curl –silent –remote-name –location <a target="_blank" rel="noopener" href="https://github.com/ceph/ceph/raw/pacific/src/cephadm/cephadm">https://github.com/ceph/ceph/raw/pacific/src/cephadm/cephadm</a><br>  root@host1:</del># ls<br>  cephadm<br>  root@host1:~# chmod +x cephadm</p>
<p>  root@host1:<del># .&#x2F;cephadm add-repo –release pacific<br>  root@host1:</del># .&#x2F;cephadm install<br>  root@host1:~# which cephadm<br>  &#x2F;usr&#x2F;sbin&#x2F;cephadm</p>
</li>
</ul>
<h2 id="Bootstrap-a-new-cluster"><a href="#Bootstrap-a-new-cluster" class="headerlink" title="Bootstrap a new cluster"></a>Bootstrap a new cluster</h2><p>The first step in creating a new Ceph cluster is running the <strong>cephadm bootstrap</strong> command on the Ceph cluster’s first host. The act of running the <strong>cephadm bootstrap</strong> command on the Ceph cluster’s first host creates the Ceph cluster’s first “monitor daemon”, and that monitor daemon needs an IP address. You must pass the IP address of the Ceph cluster’s first host to the <strong>ceph bootstrap</strong> command, so you’ll need to know the IP address of that host.</p>
<pre><code>root@host1:~# cephadm bootstrap --mon-ip &lt;host1-ip&gt; --allow-fqdn-hostname
Ceph Dashboard is now available at:

         URL: https://host1:8443/
        User: admin
    Password: btauef87vj

Enabling client.admin keyring and conf on hosts with &quot;admin&quot; label
You can access the Ceph CLI with:

    sudo /usr/sbin/cephadm shell --fsid ad30a6fc-068f-11ec-8323-000c29bf98ea -c /etc/ceph/ceph.conf -k /etc/ceph/ceph.client.admin.keyring

Please consider enabling telemetry to help improve Ceph:

    ceph telemetry on

For more information see:

    https://docs.ceph.com/docs/pacific/mgr/telemetry/

Bootstrap complete.

root@host1:~# docker ps
CONTAINER ID   IMAGE                        COMMAND                  CREATED         STATUS         PORTS     NAMES
a946ae868dbc   prom/alertmanager:v0.20.0    &quot;/bin/alertmanager -…&quot;   6 minutes ago   Up 6 minutes             ceph-ad30a6fc-068f-11ec-8323-000c29bf98ea-alertmanager.host1
504d9271b24c   ceph/ceph-grafana:6.7.4      &quot;/bin/sh -c &#39;grafana…&quot;   6 minutes ago   Up 6 minutes             ceph-ad30a6fc-068f-11ec-8323-000c29bf98ea-grafana.host1
622a5e234406   prom/prometheus:v2.18.1      &quot;/bin/prometheus --c…&quot;   6 minutes ago   Up 6 minutes             ceph-ad30a6fc-068f-11ec-8323-000c29bf98ea-prometheus.host1
6c2b0440d4c1   prom/node-exporter:v0.18.1   &quot;/bin/node_exporter …&quot;   6 minutes ago   Up 6 minutes             ceph-ad30a6fc-068f-11ec-8323-000c29bf98ea-node-exporter.host1
8bc618e9ffa3   ceph/ceph                    &quot;/usr/bin/ceph-crash…&quot;   6 minutes ago   Up 6 minutes             ceph-ad30a6fc-068f-11ec-8323-000c29bf98ea-crash.host1
b57a021238ba   ceph/ceph:v16                &quot;/usr/bin/ceph-mgr -…&quot;   7 minutes ago   Up 7 minutes             ceph-ad30a6fc-068f-11ec-8323-000c29bf98ea-mgr.host1.ltfphc
e812853ef17d   ceph/ceph:v16                &quot;/usr/bin/ceph-mon -…&quot;   7 minutes ago   Up 7 minutes             ceph-ad30a6fc-068f-11ec-8323-000c29bf98ea-mon.host1
</code></pre>
<h2 id="Enable-ceph-CLI"><a href="#Enable-ceph-CLI" class="headerlink" title="Enable ceph CLI"></a>Enable ceph CLI</h2><p>To execute ceph commands, you can also run commands like this:</p>
<pre><code>root@host1:~# cephadm shell -- ceph -s
Inferring fsid ad30a6fc-068f-11ec-8323-000c29bf98ea
Inferring config /var/lib/ceph/ad30a6fc-068f-11ec-8323-000c29bf98ea/mon.host1/config
Using recent ceph image ceph/ceph@sha256:829ebf54704f2d827de00913b171e5da741aad9b53c1f35ad59251524790eceb
  cluster:
    id:     ad30a6fc-068f-11ec-8323-000c29bf98ea
    health: HEALTH_WARN
            OSD count 0 &lt; osd_pool_default_size 3

  services:
    mon: 1 daemons, quorum host1 (age 9m)
    mgr: host1.ltfphc(active, since 10m)
    osd: 0 osds: 0 up, 0 in

  data:
    pools:   0 pools, 0 pgs
    objects: 0 objects, 0 B
    usage:   0 B used, 0 B / 0 B avail
    pgs:
</code></pre>
<p>Cephadm does not require any Ceph packages to be installed on the host. However, it recommends enabling easy access to the ceph command.</p>
<p>You can install the ceph-common package, which contains all of the ceph commands, including ceph, rbd, mount.ceph (for mounting CephFS file systems), etc.:</p>
<pre><code>root@host1:~# cephadm add-repo --release pacific
Installing repo GPG key from https://download.ceph.com/keys/release.gpg...
Installing repo file at /etc/apt/sources.list.d/ceph.list...
Updating package list...
Completed adding repo.
root@host1:~# cephadm install ceph-common
Installing packages [&#39;ceph-common&#39;]...

root@host1:~# ceph -v
ceph version 16.2.5 (0883bdea7337b95e4b611c768c0279868462204a) pacific (stable)

root@host1:~# ceph status
  cluster:
    id:     ad30a6fc-068f-11ec-8323-000c29bf98ea
    health: HEALTH_WARN
            OSD count 0 &lt; osd_pool_default_size 3

  services:
    mon: 1 daemons, quorum host1 (age 11m)
    mgr: host1.ltfphc(active, since 12m)
    osd: 0 osds: 0 up, 0 in

  data:
    pools:   0 pools, 0 pgs
    objects: 0 objects, 0 B
    usage:   0 B used, 0 B / 0 B avail
    pgs:
</code></pre>
<h2 id="Adding-additional-hosts-to-the-cluster"><a href="#Adding-additional-hosts-to-the-cluster" class="headerlink" title="Adding additional hosts to the cluster"></a>Adding additional hosts to the cluster</h2><p>To add each new host to the cluster, perform two steps:</p>
<ol>
<li><p>Install the cluster’s public SSH key in the new host’s root user’s authorized_keys file:</p>
<p> root@host1:<del># ssh-copy-id -f -i &#x2F;etc&#x2F;ceph&#x2F;ceph.pub root@host2<br> root@host1:</del># ssh-copy-id -f -i &#x2F;etc&#x2F;ceph&#x2F;ceph.pub root@host3</p>
</li>
<li><p>Tell Ceph that the new node is part of the cluster:</p>
<p> root@host1:<del># ceph orch host add host2 <host2-ip> –labels _admin<br> root@host1:</del># ceph orch host add host3 <host3-ip> –labels _admin</p>
</li>
</ol>
<p>Wait for a while until the monitor detects the new hosts. Verify the new added hosts as below.</p>
<pre><code>root@host1:~# cat /etc/ceph/ceph.conf
# minimal ceph.conf for ad30a6fc-068f-11ec-8323-000c29bf98ea
[global]
    fsid = ad30a6fc-068f-11ec-8323-000c29bf98ea
    mon_host = [v2:&lt;host2-ip&gt;:3300/0,v1:&lt;host2-ip&gt;:6789/0] [v2:&lt;host3-ip&gt;:3300/0,v1:&lt;host3-ip&gt;:6789/0] [v2:&lt;host1-ip&gt;:3300/0,v1:&lt;host1-ip&gt;:6789/0]

root@host1:~# ceph status
  cluster:
    id:     ad30a6fc-068f-11ec-8323-000c29bf98ea
    health: HEALTH_WARN
            clock skew detected on mon.host2, mon.host3
            OSD count 0 &lt; osd_pool_default_size 3

  services:
    mon: 3 daemons, quorum host1,host2,host3 (age 115s)
    mgr: host1.ltfphc(active, since 30m), standbys: host2.dqlsnk
    osd: 0 osds: 0 up, 0 in

  data:
    pools:   0 pools, 0 pgs
    objects: 0 objects, 0 B
    usage:   0 B used, 0 B / 0 B avail
    pgs:
</code></pre>
<h2 id="Adding-storage"><a href="#Adding-storage" class="headerlink" title="Adding storage"></a>Adding storage</h2><p>To add storage to the cluster, either tell Ceph to consume any available and unused device:</p>
<pre><code>ceph orch apply osd --all-available-devices
</code></pre>
<p>Or Deploy OSDs with specified storage devices.</p>
<h3 id="Listing-storage-devices"><a href="#Listing-storage-devices" class="headerlink" title="Listing storage devices"></a>Listing storage devices</h3><p>In order to deploy an OSD, there must be a storage device that is available on which the OSD will be deployed.</p>
<p>Run this command to display an inventory of storage devices on all cluster hosts:</p>
<pre><code>root@host1:~# ceph orch device ls
Hostname                            Path      Type  Serial  Size   Health   Ident  Fault  Available
host2  /dev/sdb  hdd           85.8G  Unknown  N/A    N/A    Yes
host3  /dev/sdb  hdd           85.8G  Unknown  N/A    N/A    Yes
host1  /dev/sdb  hdd           85.8G  Unknown  N/A    N/A    Yes
</code></pre>
<p>A storage device is considered available if all of the following conditions are met:</p>
<ul>
<li>The device must have no partitions.</li>
<li>The device must not have any LVM state.</li>
<li>The device must not be mounted.</li>
<li>The device must not contain a file system.</li>
<li>The device must not contain a Ceph BlueStore OSD.</li>
<li>The device must be larger than 5 GB.</li>
</ul>
<p>Ceph will not provision an OSD on a device that is not available.</p>
<h3 id="Creating-new-OSDs"><a href="#Creating-new-OSDs" class="headerlink" title="Creating new OSDs"></a>Creating new OSDs</h3><p>There are a few ways to create new OSDs:</p>
<ul>
<li><p>Tell Ceph to consume any available and unused storage device:</p>
<p>  ceph orch apply osd –all-available-devices</p>
</li>
</ul>
<p>After running the above command:</p>
<ul>
<li>If you add new disks to the cluster, they will automatically be used to create new OSDs.</li>
<li>If you remove an OSD and clean the LVM physical volume, a new OSD will be created automatically.</li>
</ul>
<p>If you want to avoid this behavior (disable automatic creation of OSD on available devices), use the <em>unmanaged</em> parameter:</p>
<pre><code>ceph orch apply osd --all-available-devices --unmanaged=true
</code></pre>
<ul>
<li><p>Create an OSD from a specific device on a specific host:</p>
<p>  ceph orch daemon add osd <em><host></em>:<em><device-path></em></p>
</li>
</ul>
<p>For example:</p>
<pre><code>ceph orch daemon add osd host1:/dev/sdb 
</code></pre>
<p>In our case, we use the following commands to create OSDs for the three nodes. We only need run the commands from host1.</p>
<pre><code>root@host1:~#   ceph orch daemon add osd host1:/dev/sdb
Created osd(s) 0 on host &#39;host1&#39;
root@host1:~# ceph orch daemon add osd host2:/dev/sdb
Created osd(s) 1 on host &#39;host2&#39;
root@host1:~# ceph orch daemon add osd host3:/dev/sdb
Created osd(s) 2 on host &#39;host3&#39;

root@host1:~# ceph status
  cluster:
    id:     ad30a6fc-068f-11ec-8323-000c29bf98ea
    health: HEALTH_WARN
            clock skew detected on mon.host2, mon.host3
            59 slow ops, oldest one blocked for 130 sec, mon.host2 has slow ops

  services:
    mon: 3 daemons, quorum host1,host2,host3 (age 2m)
    mgr: host1.ltfphc(active, since 102s), standbys: host2.dqlsnk
    osd: 3 osds: 3 up (since 7m), 3 in (since 7m)

  data:
    pools:   1 pools, 1 pgs
    objects: 0 objects, 0 B
    usage:   15 MiB used, 240 GiB / 240 GiB avail
    pgs:     1 active+clean
</code></pre>
<h3 id="Rry-Run"><a href="#Rry-Run" class="headerlink" title="Rry Run"></a>Rry Run</h3><p>The –dry-run flag causes the orchestrator to present a preview of what will happen without actually creating the OSDs.</p>
<p>For example:</p>
<pre><code>ceph orch apply osd --all-available-devices --dry-run
</code></pre>
<h2 id="Create-a-pool"><a href="#Create-a-pool" class="headerlink" title="Create a pool"></a>Create a pool</h2><p>Pools are logical partitions for storing objects. When you first deploy a cluster without creating a pool, Ceph uses the default pools for storing data.</p>
<p>By default, Ceph makes 3 replicas of RADOS objects. Ensure you have a realistic number of placement groups. Ceph recommends approximately 100 per OSD and always use the nearest power of 2.</p>
<pre><code>root@host1:~# ceph osd lspools
1 device_health_metrics
root@host1:~# ceph osd pool create datapool 128 128
pool &#39;datapool&#39; created
root@host1:~# ceph osd lspools
1 device_health_metrics
2 datapool


root@host1:~# ceph osd pool ls detail
pool 1 &#39;device_health_metrics&#39; replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 1 pgp_num 1 autoscale_mode on last_change 22 flags hashpspool stripe_width 0 pg_num_min 1 application mgr_devicehealth
pool 2 &#39;datapool&#39; replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 128 pgp_num 128 autoscale_mode on last_change 39 flags hashpspool stripe_width 0

root@host1:~# ceph osd pool get datapool all
size: 3
min_size: 2
pg_num: 128
pgp_num: 128
crush_rule: replicated_rule
hashpspool: true
nodelete: false
nopgchange: false
nosizechange: false
write_fadvise_dontneed: false
noscrub: false
nodeep-scrub: false
use_gmt_hitset: 1
fast_read: 0
pg_autoscale_mode: on
</code></pre>
<p>On the admin node, use the rbd tool to initialize the pool for use by RBD:</p>
<pre><code>[ceph: root@host1 /]# rbd pool init datapool
</code></pre>
<h2 id="Create-rbd-volume-and-map-to-a-block-device-on-the-host"><a href="#Create-rbd-volume-and-map-to-a-block-device-on-the-host" class="headerlink" title="Create rbd volume and map to a block device on the host"></a>Create rbd volume and map to a block device on the host</h2><p>The rbd command enables you to create, list, introspect and remove block device images. You can also use it to clone images, create snapshots, rollback an image to a snapshot, view a snapshot, etc.</p>
<pre><code>root@host1:~# rbd create --size 512000 datapool/rbdvol1
root@host1:~# rbd map datapool/rbdvol1
rbd: sysfs write failed
RBD image feature set mismatch. You can disable features unsupported by the kernel with &quot;rbd feature disable datapool/rbdvol1 object-map fast-diff deep-flatten&quot;.
In some cases useful info is found in syslog - try &quot;dmesg | tail&quot;.
rbd: map failed: (6) No such device or address

root@host1:~# dmesg | tail
[50268.015821] cgroup: cgroup: disabling cgroup2 socket matching due to net_prio or net_cls activation
[59168.019848] Key type ceph registered
[59168.020080] libceph: loaded (mon/osd proto 15/24)
[59168.023667] rbd: loaded (major 252)
[59168.028478] libceph: mon2 &lt;host1-ip&gt;:6789 session established
[59168.028571] libceph: mon2 &lt;host1-ip&gt;:6789 socket closed (con state OPEN)
[59168.028594] libceph: mon2 &lt;host1-ip&gt;:6789 session lost, hunting for new mon
[59175.101037] libceph: mon0 &lt;host1-ip&gt;:6789 session established
[59175.101413] libceph: client14535 fsid ad30a6fc-068f-11ec-8323-000c29bf98ea
[59175.105601] rbd: image rbdvol1: image uses unsupported features: 0x38

root@host1:~# rbd feature disable datapool/rbdvol1 object-map fast-diff deep-flatten

root@host1:~# rbd map datapool/rbdvol1
/dev/rbd0

root@host1:~# rbd showmapped
id  pool      namespace  image    snap  device
0   datapool             rbdvol1  -     /dev/rbd0

root@host1:~# lsblk
NAME                                                                                                  MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
sda                                                                                                     8:0    0  128G  0 disk
├─sda1                                                                                                  8:1    0  127G  0 part /
├─sda2                                                                                                  8:2    0    1K  0 part
└─sda5                                                                                                  8:5    0  975M  0 part
sdb                                                                                                     8:16   0   80G  0 disk
└─ceph--bc7eff08--2ac6--44a5--b941--5444c4a8600a-osd--block--b4dfb938--05af--413d--a327--18d26fc75b8d 253:0    0   80G  0 lvm
rbd0                                                                                                  252:0    0  100G  0 disk

root@host1:~# ls -la /dev/rbd/datapool/rbdvol1
lrwxrwxrwx 1 root root 10 Aug 26 19:35 /dev/rbd/datapool/rbdvol1 -&gt; ../../rbd0

root@host1:~# ls -la /dev/rbd0
brw-rw---- 1 root disk 252, 0 Aug 26 19:35 /dev/rbd0

root@host1:~# rbd status datapool/rbdvol1
Watchers:
    watcher=&lt;host1-ip&gt;:0/2778790200 client.14556 cookie=18446462598732840967

root@host1:~# rbd info datapool/rbdvol1
rbd image &#39;rbdvol1&#39;:
    size 100 GiB in 25600 objects
    order 22 (4 MiB objects)
    snapshot_count: 0
    id: 38bebe718b2f
    block_name_prefix: rbd_data.38bebe718b2f
    format: 2
    features: layering, exclusive-lock
    op_features:
    flags:
    create_timestamp: Thu Aug 26 19:31:29 2021
    access_timestamp: Thu Aug 26 19:31:29 2021
    modify_timestamp: Thu Aug 26 19:31:29 2021
</code></pre>
<h2 id="Create-filesystem-and-mount-rbd-volume"><a href="#Create-filesystem-and-mount-rbd-volume" class="headerlink" title="Create filesystem and mount rbd volume"></a>Create filesystem and mount rbd volume</h2><p>You can use Linux standard commands to create filesystem on the volume and mount it for different purpose.</p>
<h2 id="Troubleshooting"><a href="#Troubleshooting" class="headerlink" title="Troubleshooting"></a>Troubleshooting</h2><ol>
<li>Ceph does not support pacific or later on centos7.8</li>
</ol>
<p>If you are installing Ceph with version of pacific on CentOS 7.8, you may see the following issue.</p>
<pre><code>$ cat /etc/*release
CentOS Linux release 7.8.2003 (Core)
NAME=&quot;CentOS Linux&quot;

$ uname -r
5.7.12-1.el7.elrepo.x86_64

# ./cephadm add-repo --release pacific
ERROR: Ceph does not support pacific or later for this version of this linux distro and therefore cannot add a repo for it
</code></pre>
<p>You can install Ceph with version “octopus” instead.</p>
<pre><code>$ ./cephadm add-repo --release octopus
Writing repo to /etc/yum.repos.d/ceph.repo...
Enabling EPEL...
Completed adding repo
</code></pre>
<p>Note: <strong>cephadm</strong> is new in Ceph release v15.2.0 (Octopus) and does not support older versions of Ceph.</p>
<ol start="2">
<li><p>Invalid GPG Key</p>
<p> $ .&#x2F;cephadm install<br> Installing packages [‘cephadm’]…<br> Non-zero exit code 1 from yum install -y cephadm<br> yum: stdout Loaded plugins: fastestmirror, langpacks, priorities<br> yum: stdout Loading mirror speeds from cached hostfile<br> yum: stdout  * base: pxe.dev.purestorage.com<br> yum: stdout  * centosplus: pxe.dev.purestorage.com<br> yum: stdout  * epel: mirror.lax.genesisadaptive.com<br> yum: stdout  * extras: pxe.dev.purestorage.com<br> yum: stdout  * updates: pxe.dev.purestorage.com<br> yum: stdout 279 packages excluded due to repository priority protections<br> yum: stdout Resolving Dependencies<br> yum: stdout –&gt; Running transaction check<br> yum: stdout —&gt; Package cephadm.noarch 2:15.2.14-0.el7 will be installed<br> yum: stdout –&gt; Finished Dependency Resolution<br> yum: stdout<br> yum: stdout Dependencies Resolved<br> yum: stdout<br> yum: stdout &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;<br> yum: stdout  Package        Arch          Version                  Repository          Size<br> yum: stdout &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;<br> yum: stdout Installing:<br> yum: stdout  cephadm        noarch        2:15.2.14-0.el7          Ceph-noarch         55 k<br> yum: stdout<br> yum: stdout Transaction Summary<br> yum: stdout &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;<br> yum: stdout Install  1 Package<br> yum: stdout<br> yum: stdout Total download size: 55 k<br> yum: stdout Installed size: 223 k<br> yum: stdout Downloading packages:<br> yum: stdout Public key for cephadm-15.2.14-0.el7.noarch.rpm is not installed<br> yum: stdout Retrieving key from <a target="_blank" rel="noopener" href="https://download.ceph.com/keys/release.gpg">https://download.ceph.com/keys/release.gpg</a><br> yum: stderr warning: &#x2F;var&#x2F;cache&#x2F;yum&#x2F;x86_64&#x2F;7&#x2F;Ceph-noarch&#x2F;packages&#x2F;cephadm-15.2.14-0.el7.noarch.rpm: Header V4 RSA&#x2F;SHA256 Signature, key ID    460f3994: NOKEY<br> yum: stderr<br> yum: stderr<br> yum: stderr Invalid GPG Key from <a target="_blank" rel="noopener" href="https://download.ceph.com/keys/release.gpg">https://download.ceph.com/keys/release.gpg</a>: No key found in given key data<br> Traceback (most recent call last):<br>   File “.&#x2F;cephadm”, line 8432, in <module><br> main()<br>   File “.&#x2F;cephadm”, line 8420, in main<br> r &#x3D; ctx.func(ctx)<br>   File “.&#x2F;cephadm”, line 6384, in command_install<br> pkg.install(ctx.packages)<br>   File “.&#x2F;cephadm”, line 6231, in install<br> call_throws(self.ctx, [self.tool, ‘install’, ‘-y’] + ls)<br>   File “.&#x2F;cephadm”, line 1461, in call_throws<br> raise RuntimeError(‘Failed command: %s’ % ‘ ‘.join(command))<br> RuntimeError: Failed command: yum install -y cephadm</p>
</li>
</ol>
<p>Based on <a target="_blank" rel="noopener" href="https://docs.ceph.com/en/mimic/install/get-packages/">Ceph Documentation</a> , execute the following to install the release.asc key.</p>
<pre><code>$ rpm --import &#39;https://download.ceph.com/keys/release.asc&#39;
</code></pre>
<p>Install cephadm package again and it succeeds.</p>
<pre><code>$ ./cephadm install
Installing packages [&#39;cephadm&#39;]...

$ which cephadm
/usr/sbin/cephadm
</code></pre>
<ol start="3">
<li><p>Failed to add host during bootstrap</p>
<p> $ cephadm bootstrap –mon-ip 192.168.1.183<br> Adding host host1…<br> Non-zero exit code 22 from &#x2F;usr&#x2F;bin&#x2F;docker run –rm –ipc&#x3D;host –net&#x3D;host –entrypoint &#x2F;usr&#x2F;bin&#x2F;ceph -e CONTAINER_IMAGE&#x3D;docker.io&#x2F;ceph&#x2F;ceph:v15    -e NODE_NAME&#x3D;host1 -v &#x2F;var&#x2F;log&#x2F;ceph&#x2F;ccc938de-0c30-11ec-8c3f-ac1f6bc8d268:&#x2F;var&#x2F;log&#x2F;ceph:z -v &#x2F;tmp&#x2F;ceph-tmpdqxjp0ly:&#x2F;etc&#x2F;ceph&#x2F;ceph.client.admin.   keyring:z -v &#x2F;tmp&#x2F;ceph-tmpmt5hrjo9:&#x2F;etc&#x2F;ceph&#x2F;ceph.conf:z docker.io&#x2F;ceph&#x2F;ceph:v15 orch host add host1<br> &#x2F;usr&#x2F;bin&#x2F;ceph: stderr Error EINVAL: Failed to connect to host1 (host1).<br> &#x2F;usr&#x2F;bin&#x2F;ceph: stderr Please make sure that the host is reachable and accepts connections using the cephadm SSH key<br> &#x2F;usr&#x2F;bin&#x2F;ceph: stderr<br> &#x2F;usr&#x2F;bin&#x2F;ceph: stderr To add the cephadm SSH key to the host:<br> &#x2F;usr&#x2F;bin&#x2F;ceph: stderr &gt; ceph cephadm get-pub-key &gt; ~&#x2F;ceph.pub<br> &#x2F;usr&#x2F;bin&#x2F;ceph: stderr &gt; ssh-copy-id -f -i ~&#x2F;ceph.pub root@host1<br> &#x2F;usr&#x2F;bin&#x2F;ceph: stderr<br> &#x2F;usr&#x2F;bin&#x2F;ceph: stderr To check that the host is reachable:<br> &#x2F;usr&#x2F;bin&#x2F;ceph: stderr &gt; ceph cephadm get-ssh-config &gt; ssh_config<br> &#x2F;usr&#x2F;bin&#x2F;ceph: stderr &gt; ceph config-key get mgr&#x2F;cephadm&#x2F;ssh_identity_key &gt; ~&#x2F;cephadm_private_key<br> &#x2F;usr&#x2F;bin&#x2F;ceph: stderr &gt; chmod 0600 ~&#x2F;cephadm_private_key<br> &#x2F;usr&#x2F;bin&#x2F;ceph: stderr &gt; ssh -F ssh_config -i ~&#x2F;cephadm_private_key root@host1<br> ERROR: Failed to add host <host1>: Failed command: &#x2F;usr&#x2F;bin&#x2F;docker run –rm –ipc&#x3D;host –net&#x3D;host –entrypoint &#x2F;usr&#x2F;bin&#x2F;ceph -e    CONTAINER_IMAGE&#x3D;docker.io&#x2F;ceph&#x2F;ceph:v15 -e NODE_NAME&#x3D;host1 -v &#x2F;var&#x2F;log&#x2F;ceph&#x2F;ccc938de-0c30-11ec-8c3f-ac1f6bc8d268:&#x2F;var&#x2F;log&#x2F;ceph:z -v &#x2F;tmp&#x2F;   ceph-tmpdqxjp0ly:&#x2F;etc&#x2F;ceph&#x2F;ceph.client.admin.keyring:z -v &#x2F;tmp&#x2F;ceph-tmpmt5hrjo9:&#x2F;etc&#x2F;ceph&#x2F;ceph.conf:z docker.io&#x2F;ceph&#x2F;ceph:v15 orch host add    host1</p>
</li>
</ol>
<p>Note: If there are multiple networks and interfaces, be sure to choose one that will be accessible by any host accessing the Ceph cluster.</p>
<p>Make sure passwordless ssh is configured on each host.</p>
<ol start="4">
<li><p>Remove ceph cluster</p>
<p> $ cephadm  rm-cluster –fsid ccc938de-0c30-11ec-8c3f-ac1f6bc8d268 –force</p>
</li>
<li><p>ceph-common installation failure</p>
<p> $ cephadm install ceph-common<br> Installing packages [‘ceph-common’]…<br> Non-zero exit code 1 from yum install -y ceph-common<br> yum: stdout Loaded plugins: fastestmirror, langpacks, priorities<br> yum: stdout Loading mirror speeds from cached hostfile<br> yum: stdout  * base: pxe.dev.purestorage.com<br> yum: stdout  * centosplus: pxe.dev.purestorage.com<br> yum: stdout  * epel: mirror.lax.genesisadaptive.com<br> yum: stdout  * extras: pxe.dev.purestorage.com<br> yum: stdout  * updates: pxe.dev.purestorage.com<br> yum: stdout 279 packages excluded due to repository priority protections<br> yum: stdout Resolving Dependencies<br> yum: stdout –&gt; Running transaction check<br> yum: stdout —&gt; Package ceph-common.x86_64 1:10.2.5-4.el7 will be installed<br> yum: stdout –&gt; Processing Dependency: python-rbd &#x3D; 1:10.2.5-4.el7 for package: 1:ceph-common-10.2.5-4.el7.x86_64<br> yum: stdout Package python-rbd is obsoleted by python3-rbd, but obsoleting package does not provide for requirements<br> yum: stdout –&gt; Processing Dependency: python-rados &#x3D; 1:10.2.5-4.el7 for package: 1:ceph-common-10.2.5-4.el7.x86_64<br> yum: stdout Package python-rados is obsoleted by python3-rados, but obsoleting package does not provide for requirements<br> yum: stdout –&gt; Processing Dependency: hdparm for package: 1:ceph-common-10.2.5-4.el7.x86_64<br> yum: stdout –&gt; Processing Dependency: gdisk for package: 1:ceph-common-10.2.5-4.el7.x86_64<br> yum: stdout –&gt; Processing Dependency: libboost_regex-mt.so.1.53.0()(64bit) for package: 1:ceph-common-10.2.5-4.el7.x86_64<br> yum: stdout –&gt; Processing Dependency: libboost_program_options-mt.so.1.53.0()(64bit) for package: 1:ceph-common-10.2.5-4.el7.x86_64<br> yum: stdout –&gt; Running transaction check<br> yum: stdout —&gt; Package boost-program-options.x86_64 0:1.53.0-28.el7 will be installed<br> yum: stdout —&gt; Package boost-regex.x86_64 0:1.53.0-28.el7 will be installed<br> yum: stdout –&gt; Processing Dependency: libicuuc.so.50()(64bit) for package: boost-regex-1.53.0-28.el7.x86_64<br> yum: stdout –&gt; Processing Dependency: libicui18n.so.50()(64bit) for package: boost-regex-1.53.0-28.el7.x86_64<br> yum: stdout –&gt; Processing Dependency: libicudata.so.50()(64bit) for package: boost-regex-1.53.0-28.el7.x86_64<br> yum: stdout —&gt; Package ceph-common.x86_64 1:10.2.5-4.el7 will be installed<br> yum: stdout –&gt; Processing Dependency: python-rbd &#x3D; 1:10.2.5-4.el7 for package: 1:ceph-common-10.2.5-4.el7.x86_64<br> yum: stdout Package python-rbd is obsoleted by python3-rbd, but obsoleting package does not provide for requirements<br> yum: stdout –&gt; Processing Dependency: python-rados &#x3D; 1:10.2.5-4.el7 for package: 1:ceph-common-10.2.5-4.el7.x86_64<br> yum: stdout Package python-rados is obsoleted by python3-rados, but obsoleting package does not provide for requirements<br> yum: stdout —&gt; Package gdisk.x86_64 0:0.8.10-3.el7 will be installed<br> yum: stdout —&gt; Package hdparm.x86_64 0:9.43-5.el7 will be installed<br> yum: stdout –&gt; Running transaction check<br> yum: stdout —&gt; Package ceph-common.x86_64 1:10.2.5-4.el7 will be installed<br> yum: stdout –&gt; Processing Dependency: python-rbd &#x3D; 1:10.2.5-4.el7 for package: 1:ceph-common-10.2.5-4.el7.x86_64<br> yum: stdout Package python-rbd is obsoleted by python3-rbd, but obsoleting package does not provide for requirements<br> yum: stdout –&gt; Processing Dependency: python-rados &#x3D; 1:10.2.5-4.el7 for package: 1:ceph-common-10.2.5-4.el7.x86_64<br> yum: stdout Package python-rados is obsoleted by python3-rados, but obsoleting package does not provide for requirements<br> yum: stdout —&gt; Package libicu.x86_64 0:50.2-4.el7_7 will be installed<br> yum: stdout –&gt; Finished Dependency Resolution<br> yum: stdout  You could try using –skip-broken to work around the problem<br> yum: stdout  You could try running: rpm -Va –nofiles –nodigest<br> yum: stderr Error: Package: 1:ceph-common-10.2.5-4.el7.x86_64 (base)<br> yum: stderr            Requires: python-rbd &#x3D; 1:10.2.5-4.el7<br> yum: stderr            Available: 1:python-rbd-10.2.5-4.el7.x86_64 (base)<br> yum: stderr                python-rbd &#x3D; 1:10.2.5-4.el7<br> yum: stderr            Available: 2:python3-rbd-15.2.14-0.el7.x86_64 (Ceph)<br> yum: stderr                python-rbd &#x3D; 2:15.2.14-0.el7<br> yum: stderr Error: Package: 1:ceph-common-10.2.5-4.el7.x86_64 (base)<br> yum: stderr            Requires: python-rados &#x3D; 1:10.2.5-4.el7<br> yum: stderr            Available: 1:python-rados-10.2.5-4.el7.x86_64 (base)<br> yum: stderr                python-rados &#x3D; 1:10.2.5-4.el7<br> yum: stderr            Available: 2:python3-rados-15.2.14-0.el7.x86_64 (Ceph)<br> yum: stderr                python-rados &#x3D; 2:15.2.14-0.el7<br> Traceback (most recent call last):<br>   File “&#x2F;usr&#x2F;sbin&#x2F;cephadm”, line 6242, in <module><br> r &#x3D; args.func()<br>   File “&#x2F;usr&#x2F;sbin&#x2F;cephadm”, line 5073, in command_install<br> pkg.install(args.packages)<br>   File “&#x2F;usr&#x2F;sbin&#x2F;cephadm”, line 4931, in install<br> call_throws([self.tool, ‘install’, ‘-y’] + ls)<br>   File “&#x2F;usr&#x2F;sbin&#x2F;cephadm”, line 1112, in call_throws<br> raise RuntimeError(‘Failed command: %s’ % ‘ ‘.join(command))<br> RuntimeError: Failed command: yum install -y ceph-common</p>
</li>
<li><p>cephadm log</p>
</li>
</ol>
<p>&#x2F;var&#x2F;log&#x2F;ceph&#x2F;cephadm.log</p>
<ol start="7">
<li><p>rbd image map failed</p>
<p> [ceph: root@host1 &#x2F;]# rbd map datapool&#x2F;rbdvol1<br> modinfo: ERROR: Module alias rbd not found.<br> modprobe: FATAL: Module rbd not found in directory &#x2F;lib&#x2F;modules&#x2F;5.7.12-1.el7.elrepo.x86_64<br> rbd: failed to load rbd kernel module (1)<br> rbd: sysfs write failed<br> In some cases useful info is found in syslog - try “dmesg | tail”.<br> rbd: map failed: (2) No such file or directory</p>
<p> [root@host1 ~]# modprobe rbd<br> [root@host1 ~]# lsmod | grep rbd<br> rbd                   106496  0<br> libceph               331776  1 rbd</p>
</li>
<li><p>rbd image map failed on other cluster nodes</p>
<p> [ceph: root@host2 &#x2F;]# rbd map datapool&#x2F;rbdvol5 –id admin<br> 2021-09-21T19:49:49.384+0000 7f91ea781500 -1 auth: unable to find a keyring on &#x2F;etc&#x2F;ceph&#x2F;ceph.client.admin.keyring,&#x2F;etc&#x2F;ceph&#x2F;ceph.keyring,&#x2F;etc&#x2F;ceph&#x2F;keyring,&#x2F;etc&#x2F;ceph&#x2F;keyring.bin,: (2) No such file or directory<br> rbd: sysfs write failed<br> 2021-09-21T19:49:49.387+0000 7f91ea781500 -1 auth: unable to find a keyring on &#x2F;etc&#x2F;ceph&#x2F;ceph.client.admin.keyring,&#x2F;etc&#x2F;ceph&#x2F;ceph.keyring,&#x2F;etc&#x2F;ceph&#x2F;keyring,&#x2F;etc&#x2F;ceph&#x2F;keyring.bin,: (2) No such file or directory<br> 2021-09-21T19:49:49.387+0000 7f91ea781500 -1 AuthRegistry(0x5633b09431e0) no keyring found at &#x2F;etc&#x2F;ceph&#x2F;ceph.client.admin.keyring,&#x2F;etc&#x2F;ceph&#x2F;ceph.keyring,&#x2F;etc&#x2F;ceph&#x2F;keyring,&#x2F;etc&#x2F;ceph&#x2F;keyring.bin,, disabling cephx<br> 2021-09-21T19:49:49.388+0000 7f91ea781500 -1 auth: unable to find a keyring on &#x2F;etc&#x2F;ceph&#x2F;ceph.client.admin.keyring,&#x2F;etc&#x2F;ceph&#x2F;ceph.keyring,&#x2F;etc&#x2F;ceph&#x2F;keyring,&#x2F;etc&#x2F;ceph&#x2F;keyring.bin,: (2) No such file or directory<br> 2021-09-21T19:49:49.388+0000 7f91ea781500 -1 AuthRegistry(0x7fffd357c350) no keyring found at &#x2F;etc&#x2F;ceph&#x2F;ceph.client.admin.keyring,&#x2F;etc&#x2F;ceph&#x2F;ceph.keyring,&#x2F;etc&#x2F;ceph&#x2F;keyring,&#x2F;etc&#x2F;ceph&#x2F;keyring.bin,, disabling cephx<br> 2021-09-21T19:49:49.389+0000 7f91d9b68700 -1 monclient(hunting): handle_auth_bad_method server allowed_methods [2] but i only support [1]<br> 2021-09-21T19:49:49.389+0000 7f91da369700 -1 monclient(hunting): handle_auth_bad_method server allowed_methods [2] but i only support [1]<br> 2021-09-21T19:49:49.389+0000 7f91dab6a700 -1 monclient(hunting): handle_auth_bad_method server allowed_methods [2] but i only support [1]<br> 2021-09-21T19:49:49.389+0000 7f91ea781500 -1 monclient: authenticate NOTE: no keyring found; disabled cephx authentication<br> rbd: couldnot connect to the cluster!<br> In some cases useful info is found in syslog - try “dmesg | tail”.<br> rbd: map failed: (22) Invalid argument</p>
<p> [ceph: root@host2 &#x2F;]# ls &#x2F;etc&#x2F;ceph<br> ceph.conf  rbdmap</p>
</li>
</ol>
<p>Copy the &#x2F;etc&#x2F;ceph&#x2F;ceph.keyring from admin node host1 to host2</p>
<pre><code>[ceph: root@host2 /]# ls /etc/ceph
ceph.conf  ceph.keyring  rbdmap

[ceph: root@host2 /]# rbd map datapool/rbdvol5
[ceph: root@host2 /]# rbd device list
id  pool      namespace  image    snap  device
0   datapool             rbdvol5  -     /dev/rbd0
</code></pre>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a target="_blank" rel="noopener" href="https://docs.ceph.com/en/latest/releases/">https://docs.ceph.com/en/latest/releases/</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.ceph.com/en/mimic/start/intro/">https://docs.ceph.com/en/mimic/start/intro/</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.ceph.com/en/latest/cephadm/install/">https://docs.ceph.com/en/latest/cephadm/install/</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.ceph.com/en/latest/cephadm/osd/#cephadm-deploy-osds">https://docs.ceph.com/en/latest/cephadm/osd/#cephadm-deploy-osds</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.ceph.com/en/latest/rados/operations/pools/">https://docs.ceph.com/en/latest/rados/operations/pools/</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.ceph.com/en/latest/rados/configuration/pool-pg-config-ref/">https://docs.ceph.com/en/latest/rados/configuration/pool-pg-config-ref/</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.ceph.com/en/latest/rbd/rados-rbd-cmds/">https://docs.ceph.com/en/latest/rbd/rados-rbd-cmds/</a></li>
<li><a target="_blank" rel="noopener" href="https://sabaini.at/pages/ceph-cheatsheet.html">https://sabaini.at/pages/ceph-cheatsheet.html</a></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.flamingbytes.com/blog/capture-and-analyze-network-packets-with-tcpdump/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/logo/FlamingBytes-icon-64x64-1.png">
      <meta itemprop="name" content="relentlesstorm">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FlamingBytes">
      <meta itemprop="description" content="Stay hungry, stay foolish">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | FlamingBytes">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/blog/capture-and-analyze-network-packets-with-tcpdump/" class="post-title-link" itemprop="url">Capture and analyze network packets with tcpdump</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-08-20 07:00:00" itemprop="dateCreated datePublished" datetime="2021-08-20T07:00:00-07:00">2021-08-20</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-10-22 11:28:20" itemprop="dateModified" datetime="2023-10-22T11:28:20-07:00">2023-10-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Tech/" itemprop="url" rel="index"><span itemprop="name">Tech</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Tech/Linux/" itemprop="url" rel="index"><span itemprop="name">Linux</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="Capture-packets-with-tcpdump"><a href="#Capture-packets-with-tcpdump" class="headerlink" title="Capture packets with tcpdump"></a>Capture packets with tcpdump</h2><p>In this example, we only capture 1000 packets(-c1000) and use IP addresses and ports(-nn) for easier analysis. The raw packets are written to file “tcpdump.1000” for further analsis.</p>
<pre><code>$ tcpdump -i eth5 -c1000 -nn -w tcpdump.1000
</code></pre>
<h2 id="View-the-packets-data"><a href="#View-the-packets-data" class="headerlink" title="View the packets data"></a>View the packets data</h2><p>We can use tcpdump to view the packets directly.</p>
<pre><code>$ tcpdump -nn -r tcpdump.1000 | more

reading from file tcpdump.1000, link-type EN10MB (Ethernet)

22:42:10.018758 IP 192.168.1.18.980 &gt; 192.168.1.16.2049: Flags [P.], seq 1:16545, ack 72, win 501, options [nop,nop,TS val 4292822374 ecr 2230894482], length 16544: NFS request xid 2912663971 16540 getattr fh 0,0/22
22:42:10.018895 IP 192.168.1.16.2049 &gt; 192.168.1.18.980: Flags [.], ack 16545, win 9508, options [nop,nop,TS val 2230894483 ecr 4292822374], length 0
22:42:10.021125 IP 192.168.1.16.2049 &gt; 192.168.1.18.980: Flags [P.], seq 72:144, ack 16545, win 9596, options [nop,nop,TS val 2230894485 ecr 4292822374], length 72: NFS reply xid 781957539 reply ok 68


22:42:10.021400 IP 192.168.1.18.980 &gt; 192.168.1.16.2049: Flags [P.], seq 16545:33089, ack 144, win 501, options [nop,nop,TS val 4292822377 ecr 2230894485], length 16544: NFS request xid 2929441187 16540 getattr fh 0,0/22
22:42:10.021536 IP 192.168.1.16.2049 &gt; 192.168.1.18.980: Flags [.], ack 33089, win 9508, options [nop,nop,TS val 2230894485 ecr 4292822377], length 0
22:42:10.023219 ARP, Request who-has 70.0.69.235 tell 70.0.193.122, length 46
22:42:10.023558 IP 192.168.1.16.2049 &gt; 192.168.1.18.980: Flags [P.], seq 144:216, ack 33089, win 9596, options [nop,nop,TS val 2230894487 ecr 4292822377], length 72: NFS reply xid 798734755 reply ok 68


22:42:10.023844 IP 192.168.1.18.980 &gt; 192.168.1.16.2049: Flags [P.], seq 33089:49633, ack 216, win 501, options [nop,nop,TS val 4292822379 ecr 2230894487], length 16544: NFS request xid 2946218403 16540 getattr fh 0,0/22
22:42:10.023962 IP 192.168.1.16.2049 &gt; 192.168.1.18.980: Flags [.], ack 49633, win 9508, options [nop,nop,TS val 2230894488 ecr 4292822379], length 0
22:42:10.025962 IP 192.168.1.16.2049 &gt; 192.168.1.18.980: Flags [P.], seq 216:288, ack 49633, win 9596, options [nop,nop,TS val 2230894490 ecr 4292822379], length 72: NFS reply xid 815511971 reply ok 68

&lt;omitted...&gt;
</code></pre>
<p>We also can view the data with wireshark GUI. We can use the filter to only display the data we are interested in. In this case, we only display the data related the ip address “192.168.1.18”. The wireshare can be installed on the desktop and open the captured packets data file.</p>
<p><img src="/images/tcpdump-wireshark.png" alt="Image"></p>
<h2 id="Understand-the-tcpdump-output"><a href="#Understand-the-tcpdump-output" class="headerlink" title="Understand the tcpdump output"></a>Understand the tcpdump output</h2><ul>
<li><p>The first field, <strong>22:42:10.021125</strong>, represents the timestamp of the captured packet.</p>
</li>
<li><p>The next field, <strong>IP</strong>, represents the network layer protocol, in this case, IPv4.</p>
</li>
<li><p>The next field, <strong>192.168.1.16.2049 &gt; 192.168.1.18.980</strong>, is the source and destination IP address and port.</p>
</li>
<li><p>The next field, <strong>Flags [P.]</strong>, represents the TCP flags. The typical values for this field include the following.</p>
</li>
</ul>
<p><img src="/images/tcpdump-tcp-flags.png" alt="Image"></p>
<ul>
<li><p>The next field, <strong>seq 72:144</strong>, is the sequence number of the data contained in the packet.  It means the packet contains bytes 72 to 144.</p>
</li>
<li><p>The next field, <strong>ack 16545</strong>, is the Ack number. For the side of receiving data, this field represents the next expected byte of data. In this case, the Ack number for the next expected packet would be 16545.</p>
</li>
<li><p>The next field, <strong>win 9596</strong>, is the window size. It represents the number of bytes available in the receiving buffer.</p>
</li>
<li><p>Followed by a field, <strong>length 72</strong>, which represents the length in bytes of the data.</p>
</li>
</ul>
<p>In the above example, the data are sending from 192.168.1.18 to 192.168.1.16. The average packet size is 16k which is sent over NFSv4.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.flamingbytes.com/blog/useful-tools-to-analyze-network-latency/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/logo/FlamingBytes-icon-64x64-1.png">
      <meta itemprop="name" content="relentlesstorm">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FlamingBytes">
      <meta itemprop="description" content="Stay hungry, stay foolish">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | FlamingBytes">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/blog/useful-tools-to-analyze-network-latency/" class="post-title-link" itemprop="url">Useful tools to analyze network latency</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-08-13 07:00:00" itemprop="dateCreated datePublished" datetime="2021-08-13T07:00:00-07:00">2021-08-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-10-22 11:28:20" itemprop="dateModified" datetime="2023-10-22T11:28:20-07:00">2023-10-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Tech/" itemprop="url" rel="index"><span itemprop="name">Tech</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Tech/Linux/" itemprop="url" rel="index"><span itemprop="name">Linux</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="ping"><a href="#ping" class="headerlink" title="ping"></a>ping</h2><p>Ping is one of the most basic commands in network management, verifying network connectivity through the roundtrip times taken by the ICMP protocol packets sent to a target host.</p>
<p>ping - send ICMP ECHO_REQUEST to network hosts</p>
<ul>
<li>-c count</li>
</ul>
<p>Stop after sending <em>count</em> ECHO_REQUEST packets. With deadline option, ping waits for count ECHO_REPLY packets, until the timeout expires.</p>
<ul>
<li>-i interval</li>
</ul>
<p>Wait interval seconds between sending each packet. The default is to wait for one  second  between each packet normally, or not to wait in flood mode. Only super-user may set interval to values less 0.2 seconds.</p>
<pre><code>$ ping 10.10.1.17 -c 1000 -i 0.010
PING 10.10.1.17 (10.10.1.17) 56(84) bytes of data.
64 bytes from 10.10.1.17: icmp_seq=1 ttl=64 time=0.176 ms
64 bytes from 10.10.1.17: icmp_seq=2 ttl=64 time=0.173 ms
&lt;omitted...&gt;
64 bytes from 10.10.1.17: icmp_seq=999 ttl=64 time=0.197 ms
64 bytes from 10.10.1.17: icmp_seq=1000 ttl=64 time=0.195 ms

--- 10.10.1.17 ping statistics ---
1000 packets transmitted, 1000 received, 0% packet loss, time 10992ms
rtt min/avg/max/mdev = 0.096/0.173/0.210/0.025 ms
</code></pre>
<p>Round-trip time (RTT) is the duration, measured in milliseconds, from when the source server sends a request to when it receives a response from a target server. It’s a key performance metric to measure network latency.</p>
<p>Actual round trip time can be influenced by:</p>
<ul>
<li>Distance – The length a signal has to travel correlates with the time taken for a request to reach a server.</li>
<li>Transmission medium – The medium used to route a signal (e.g., copper wire, fiber optic cables) can impact how quickly a request is received by a server and routed back to a user.</li>
<li>Number of network hops – Intermediate routers or servers take time to process a signal, increasing RTT. The more hops a signal has to travel through, the higher the RTT.</li>
<li>Traffic levels – RTT typically increases when a network is congested with high levels of traffic. Conversely, low traffic times can result in decreased RTT.</li>
<li>Server response time – The time taken for a target server to respond to a request depends on its processing capacity, the number of requests being handled and the nature of the request (i.e., how much server-side work is required). A longer server response time increases RTT.</li>
</ul>
<h2 id="traceroute"><a href="#traceroute" class="headerlink" title="traceroute"></a>traceroute</h2><p>A traceroute displays the path that the signal took as it traveled around the Internet to the website. It also displays times which are the response times that occurred at each stop along the route. If there is a connection problem or latency connecting to a site, it will show up in these times. You will be able to identify which of the stops (also called ‘hops’) along the route is the culprit.</p>
<pre><code>$ for i in `seq 1 5`; do traceroute 10.10.1.17;sleep 3; done
traceroute to 10.10.1.17 (10.10.1.17), 30 hops max, 60 byte packets
 1  10.10.1.17 (10.10.1.17)  0.181 ms  0.086 ms  0.084 ms
traceroute to 10.10.1.17 (10.10.1.17), 30 hops max, 60 byte packets
 1  10.10.1.17 (10.10.1.17)  0.179 ms  0.087 ms  0.081 ms
traceroute to 10.10.1.17 (10.10.1.17), 30 hops max, 60 byte packets
 1  10.10.1.17 (10.10.1.17)  0.175 ms  0.087 ms  0.081 ms
traceroute to 10.10.1.17 (10.10.1.17), 30 hops max, 60 byte packets
 1  10.10.1.17 (10.10.1.17)  0.183 ms  0.073 ms  0.081 ms
traceroute to 10.10.1.17 (10.10.1.17), 30 hops max, 60 byte packets
 1  10.10.1.17 (10.10.1.17)  0.177 ms  0.080 ms  0.081 ms
</code></pre>
<p>-<br>Hop Number – the first column is simply the number of the hop along the route.</p>
<p>-<br>RTT Columns – The last three columns display the round trip time (RTT) for the packet to reach that point and return. It is listed in milliseconds. There are three columns because the traceroute sends three separate signal packets. This is to display consistency in the route.</p>
<h2 id="netperf"><a href="#netperf" class="headerlink" title="netperf"></a>netperf</h2><p>Netperf is a benchmark that can be used to measure the performance of many different types of networking. It provides tests for both unidirectional throughput, and end-to-end latency. The environments currently measureable by netperf include:</p>
<ul>
<li><p>TCP and UDP via BSD Sockets for both IPv4 and IPv6</p>
</li>
<li><p>DLPI</p>
</li>
<li><p>Unix Domain Sockets</p>
</li>
<li><p>SCTP for both IPv4 and IPv6</p>
<p>  netperf -h</p>
<p>  Usage: netperf [global options] – [test options]</p>
<p>  Global options:<br>  -a send,recv      Set the local send,recv buffer alignment<br>  -A send,recv      Set the remote send,recv buffer alignment<br>  -B brandstr       Specify a string to be emitted with brief output<br>  -c [cpu_rate]     Report local CPU usage<br>  -C [cpu_rate]     Report remote CPU usage<br>  -d                Increase debugging output<br>  -D [secs,units] * Display interim results at least every secs seconds<br>                    using units as the initial guess for units per second<br>  -f G|M|K|g|m|k    Set the output units<br>  -F fill_file      Pre-fill buffers with data from fill_file<br>  -h                Display this text<br>  -H name|ip,fam *  Specify the target machine and&#x2F;or local ip and family<br>  -i max,min        Specify the max and min number of iterations (15,1)<br>  -I lvl[,intvl]    Specify confidence level (95 or 99) (99)<br>                    and confidence interval in percentage (10)<br>  -j                Keep additional timing statistics<br>  -l testlen        Specify test duration (&gt;0 secs) (&lt;0 bytes|trans)<br>  -L name|ip,fam *  Specify the local ip|name and address family<br>  -o send,recv      Set the local send,recv buffer offsets<br>  -O send,recv      Set the remote send,recv buffer offset<br>  -n numcpu         Set the number of processors for CPU util<br>  -N                Establish no control connection, do ‘send’ side only<br>  -p port,lport*    Specify netserver port number and&#x2F;or local port<br>  -P 0|1            Donot&#x2F;Do display test headers<br>  -r                Allow confidence to be hit on result only<br>  -s seconds        Wait seconds between test setup and test start<br>  -S                Set SO_KEEPALIVE on the data connection<br>  -t testname       Specify test to perform<br>  -T lcpu,rcpu      Request netperf&#x2F;netserver be bound to local&#x2F;remote cpu<br>  -v verbosity      Specify the verbosity level<br>  -W send,recv      Set the number of send,recv buffers<br>  -v level          Set the verbosity level (default 1, min 0)<br>  -V                Display the netperf version and exit<br>  For those options taking two parms, at least one must be specified;<br>  specifying one value without a comma will set both parms to that<br>  value, specifying a value with a leading comma will set just the second<br>  parm, a value with a trailing comma will set just the first. To set<br>  each parm to unique values, specify both and separate them with a<br>  comma.</p>
<ul>
<li>For these options taking two parms, specifying one value with no comma<br>  will only set the first parms and will leave the second at the default<br>  value. To set the second value it must be preceded with a comma or be a<br>  comma-separated pair. This is to retain previous netperf behaviour.</li>
</ul>
<p>  $ wget -O netperf-2.5.0.tar.gz -c <a target="_blank" rel="noopener" href="https://codeload.github.com/HewlettPackard/netperf/tar.gz/netperf-2.5.0">https://codeload.github.com/HewlettPackard/netperf/tar.gz/netperf-2.5.0</a><br>  $ tar xf netperf-2.5.0.tar.gz &amp;&amp; cd netperf-netperf-2.5.0<br>  $ .&#x2F;configure &amp;&amp; make &amp;&amp; make install</p>
<p>  [<a href="mailto:&#x72;&#111;&#x6f;&#116;&#x40;&#49;&#x30;&#x2e;&#x30;&#46;&#48;&#46;&#49;&#x37;">&#x72;&#111;&#x6f;&#116;&#x40;&#49;&#x30;&#x2e;&#x30;&#46;&#48;&#46;&#49;&#x37;</a>]$ netserver -D<br>  [<a href="mailto:&#x72;&#x6f;&#x6f;&#x74;&#64;&#x31;&#x30;&#46;&#x30;&#46;&#x30;&#46;&#x31;&#54;">&#x72;&#x6f;&#x6f;&#x74;&#64;&#x31;&#x30;&#46;&#x30;&#46;&#x30;&#46;&#x31;&#54;</a>]$ netperf -H 10.10.1.17 -l -1000000 -t TCP_RR -w 10ms -b 1 -v 2 – -O min_latency,mean_latency,max_latency,stddev_latency,transaction_rate<br>  Packet rate control is not compiled in.<br>  Packet burst size is not compiled in.<br>  MIGRATED TCP REQUEST&#x2F;RESPONSE TEST from 0.0.0.0 (0.0.0.0) port 0 AF_INET to 10.10.1.17 (10.10.1.17) port 0 AF_INET : first burst 0<br>  Minimum      Mean         Maximum      Stddev       Transaction<br>  Latency      Latency      Latency      Latency      Rate<br>  Microseconds Microseconds Microseconds Microseconds Tran&#x2F;s</p>
<p>  63           84.92        2980         7.86         11740.092</p>
</li>
</ul>
<h2 id="iperf"><a href="#iperf" class="headerlink" title="iperf"></a>iperf</h2><p>iPerf3 is a tool for active measurements of the maximum achievable bandwidth on IP networks. It supports tuning of various parameters related to timing, buffers and protocols (TCP, UDP, SCTP with IPv4 and IPv6). For each test it reports the bandwidth, loss, and other parameters.</p>
<h2 id="lldp"><a href="#lldp" class="headerlink" title="lldp"></a>lldp</h2><p>LLDP (Link Layer Discovery Protocol) can be essential in the situations of complex network-server infrastructure configurations and it’s extremely helpful in case there is no direct access to our setup but we need to determine what network ports on the switches are our servers NIC cards connected to.</p>
<p>Below example shows how to install and enable LLDP Daemon on CentOS and check what are the corresponding neighbor ports connected to the server network cards.</p>
<pre><code>$ yum install lldpd
$ systemctl --now enable lldpd
  
$ lldpcli show neighbors
-------------------------------------------------------------------------------
LLDP neighbors:
-------------------------------------------------------------------------------
Interface:    enp6s0f1, via: LLDP, RID: 1, Time: 0 day, 00:01:29
  Chassis:
    ChassisID:    mac 00:1c:73:82:07:ee
    SysName:      xx-ay-01.06.09
    SysDescr:     Arista Networks EOS version 4.16.6M running on an Arista Networks Lab-71x-28
    MgmtIP:       10.0.254.9
    Capability:   Bridge, on
    Capability:   Router, on
  Port:
    PortID:       ifname Ethernet17
    TTL:          120
-------------------------------------------------------------------------------
</code></pre>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a target="_blank" rel="noopener" href="https://hewlettpackard.github.io/netperf/">https://hewlettpackard.github.io/netperf/</a></li>
<li><a target="_blank" rel="noopener" href="https://iperf.fr/">https://iperf.fr/</a></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.flamingbytes.com/blog/iouring-a-modern-asynchronous-i-o-interface-for-linux/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/logo/FlamingBytes-icon-64x64-1.png">
      <meta itemprop="name" content="relentlesstorm">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FlamingBytes">
      <meta itemprop="description" content="Stay hungry, stay foolish">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | FlamingBytes">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/blog/iouring-a-modern-asynchronous-i-o-interface-for-linux/" class="post-title-link" itemprop="url">Iouring - A modern asynchronous I/O interface for Linux</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-08-04 07:00:00" itemprop="dateCreated datePublished" datetime="2021-08-04T07:00:00-07:00">2021-08-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-10-22 11:28:20" itemprop="dateModified" datetime="2023-10-22T11:28:20-07:00">2023-10-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Tech/" itemprop="url" rel="index"><span itemprop="name">Tech</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Tech/Linux/" itemprop="url" rel="index"><span itemprop="name">Linux</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>The Linux kernel has had asynchronous I&#x2F;O since version 2.5, but it was seen as difficult to use and inefficient.</p>
<p>io_uring (previously known as aioring) is a Linux kernel system call interface for storage device asynchronous I&#x2F;O operations addressing performance issues with similar interfaces provided by functions like read()&#x2F;write() or aio_read()&#x2F;aio_write() etc. for operations on data accessed by file descriptors.</p>
<p>It was primarily developed by Jens Axboe at Facebook.</p>
<p>Internally it works by creating two buffers dubbed as “queue rings” (circular buffers) for storage of submission and completion of I&#x2F;O requests (for storage devices, submission queue (SQ) and completion queue (CQ) respectively). Keeping these buffers shared between the kernel and application helps to boost the I&#x2F;O performance by eliminating the need to issue extra and expensive system calls to copy these buffers between the two.According to the io_uring design paper, the SQ buffer is writable only by consumer application, and CQ - by kernel.</p>
<p>The API provided by liburing library for userspace (applications) can be used to interact with the kernel interface more easily.</p>
<p>Both kernel interface and library were adapted in Linux 5.1 kernel version.</p>
<p><img src="/images/iouring.png" alt="Image"></p>
<p>Credit to: Donald Hunter (A visual representation of the io_uring submission and completion queues)</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a target="_blank" rel="noopener" href="https://developers.redhat.com/articles/2023/04/12/why-you-should-use-iouring-network-io#:~:text=The%20main%20benefit%20of%20io_uring,file%20and%20network%20I%2FO.">Why you should use io_uring for network I&#x2F;O</a></li>
<li><a target="_blank" rel="noopener" href="https://dl.acm.org/doi/pdf/10.1145/3534056.3534945">https://dl.acm.org/doi/pdf/10.1145/3534056.3534945</a></li>
<li><a target="_blank" rel="noopener" href="https://kernel-recipes.org/en/2019/talks/faster-io-through-io_uring/">https://kernel-recipes.org/en/2019/talks/faster-io-through-io_uring&#x2F;</a></li>
<li><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Io_uring">https://en.wikipedia.org/wiki/Io_uring</a></li>
<li><a target="_blank" rel="noopener" href="https://kernel.dk/io_uring.pdf">https://kernel.dk/io_uring.pdf</a></li>
<li><a target="_blank" rel="noopener" href="https://developers.mattermost.com/blog/hands-on-iouring-go/">https://developers.mattermost.com/blog/hands-on-iouring-go/</a></li>
<li><a target="_blank" rel="noopener" href="https://lwn.net/Articles/810414/">https://lwn.net/Articles/810414/</a></li>
<li><a target="_blank" rel="noopener" href="https://lwn.net/Articles/776703/">https://lwn.net/Articles/776703/</a></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="Previous page" aria-label="Previous page" href="/page/20/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/20/">20</a><span class="page-number current">21</span><a class="page-number" href="/page/22/">22</a><span class="space">&hellip;</span><a class="page-number" href="/page/27/">27</a><a class="extend next" rel="next" title="Next page" aria-label="Next page" href="/page/22/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2023</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">relentlesstorm</span>
  </div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/mist/" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>







  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>





</body>
</html>
