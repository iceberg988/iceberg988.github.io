<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/logo/FlamingBytes-icon-64x64-1.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/logo/FlamingBytes-icon-64x64-1.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/logo/FlamingBytes-icon-64x64-1.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" integrity="sha256-CTSx/A06dm1B063156EVh15m6Y67pAjZZaQc89LLSrU=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"www.flamingbytes.com","root":"/","images":"/images","scheme":"Mist","darkmode":true,"version":"8.18.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":"default"},"fold":{"enable":true,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="Stay hungry, stay foolish">
<meta property="og:type" content="website">
<meta property="og:title" content="FlamingBytes">
<meta property="og:url" content="https://www.flamingbytes.com/page/23/index.html">
<meta property="og:site_name" content="FlamingBytes">
<meta property="og:description" content="Stay hungry, stay foolish">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="relentlesstorm">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://www.flamingbytes.com/page/23/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"en","comments":"","permalink":"","path":"page/23/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>FlamingBytes</title>
  







<!-- Google Adsense-->
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8578408127828851"
     crossorigin="anonymous"></script>

<!-- Google tag (gtag.js) for analytics-->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-B8PQ47L2H0"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-B8PQ47L2H0');
</script>

  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">FlamingBytes</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories<span class="badge">10</span></a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags<span class="badge">101</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives<span class="badge">263</span></a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="relentlesstorm"
      src="/images/logo/FlamingBytes-icon-64x64-1.png">
  <p class="site-author-name" itemprop="name">relentlesstorm</p>
  <div class="site-description" itemprop="description">Stay hungry, stay foolish</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">263</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">101</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="mailto:relentlesstorm@gmail.com" title="E-Mail → mailto:relentlesstorm@gmail.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.flamingbytes.com/blog/blktrace-a-block-layer-io-tracing-utility/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/logo/FlamingBytes-icon-64x64-1.png">
      <meta itemprop="name" content="relentlesstorm">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FlamingBytes">
      <meta itemprop="description" content="Stay hungry, stay foolish">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | FlamingBytes">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/blog/blktrace-a-block-layer-io-tracing-utility/" class="post-title-link" itemprop="url">blktrace - A block layer IO tracing utility</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-03-11 08:00:00" itemprop="dateCreated datePublished" datetime="2021-03-11T08:00:00-08:00">2021-03-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-10-22 11:28:20" itemprop="dateModified" datetime="2023-10-22T11:28:20-07:00">2023-10-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Tech/" itemprop="url" rel="index"><span itemprop="name">Tech</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Tech/Performance/" itemprop="url" rel="index"><span itemprop="name">Performance</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="What-can-blktrace-do"><a href="#What-can-blktrace-do" class="headerlink" title="What can blktrace do?"></a>What can blktrace do?</h2><p>Let’s dive into the block device layer and see how the I&#x2F;O are handled in disk queues.</p>
<p>The following stack shows the I&#x2F;O paths including the block device layer. The application can issue I&#x2F;O requests directly to block device or through file systems. In the following sections, let’s dig into the block device layer with blktrace in order to understand the I&#x2F;O pattern and disk queue activities.</p>
<pre><code>        Applications
        |      |   |  
        V      |   | 
  File systems |   |
        |      |   |
        V      |   |
 Page Cache &lt;--|   | 
        |          | 
        V          V
Block I/O Layer: Request Queues
        |
        V 
  SCSI Drivers
        |
        V
 Physical Devices               
</code></pre>
<h2 id="Don’t-forget-iostat"><a href="#Don’t-forget-iostat" class="headerlink" title="Don’t forget iostat"></a>Don’t forget iostat</h2><p>iostat is always the first place to understand the I&#x2F;O characteristics before we turn to other advanced utilities like blktrace.</p>
<p>It provides the following information for the disk IOs.</p>
<ul>
<li>Number of read&#x2F;write merges per second</li>
<li>Number of reads&#x2F;writes per second</li>
<li>Average I&#x2F;O request size(in sectors)</li>
<li>Average request queue size</li>
<li>Average I&#x2F;O wait time</li>
</ul>
<p>If any of the above metrics indicates disk I&#x2F;O performance concerns and it’s not sufficient to help us explain the performance issue, we can turn to blktrace or other tracing utilities for more insights.</p>
<h2 id="blktrace-and-blkparse"><a href="#blktrace-and-blkparse" class="headerlink" title="blktrace and blkparse"></a>blktrace and blkparse</h2><p>To trace the target block device:</p>
<pre><code>$ blktrace -d /dev/&lt;sd-device-name&gt; -D &lt;trace-raw-data-save-dir&gt; -w &lt;trace-time-in-seconds&gt;
</code></pre>
<p>To parse the blktrace data:</p>
<pre><code>$ blkparse -i &lt;sd-device-name&gt; -D &lt;trace-raw-data-save-dir&gt; -o blkparse.&lt;sd-device-name&gt;.out -d blktrace.bin
</code></pre>
<p>blkparse output snippet:</p>
<pre><code>  8,0    7        3     0.992335623  4180  A  WS 680911952 + 8 &lt;- (8,2) 679885904
  8,0    7        4     0.992336407  4180  Q  WS 680911952 + 8 [jbd2/dm-7-8]
  8,0    7        5     0.992338784  4180  G  WS 680911952 + 8 [jbd2/dm-7-8]
  8,0    7        6     0.992339977  4180  I  WS 680911952 + 8 [jbd2/dm-7-8]
  8,0    7        7     0.992341444  4180  D  WS 680911952 + 8 [jbd2/dm-7-8]
  8,0   56        1     0.992499505     0  C  WS 680911952 + 8 [0]
  8,0   47        7     0.991930131  4180  A  WS 680911920 + 8 &lt;- (8,2) 679885872
  8,0   47        8     0.991930522  4180  Q  WS 680911920 + 8 [jbd2/dm-7-8]
  8,0   47        9     0.991932697  4180  M  WS 680911920 + 8 [jbd2/dm-7-8]
</code></pre>
<p>The columns are Dev major,minor, CPU id, Sequence number, Timestamp, PID, Event, Operation, Start block + number of blocks(offset), Process name.</p>
<p>In the above example, The first IO starts at block 680911952 with the offset of 8 blocks. It is handled in the following sequence.</p>
<ul>
<li>Remapped to a different device(8,2)</li>
<li>Handled by the request queue code</li>
<li>Get the request</li>
<li>Inserted to the request queue</li>
<li>Dispatch to device driver</li>
<li>Completion</li>
</ul>
<p>The second IO starts at block 680911920 with the offset of 8 blocks. It’s handled in the following sequence.</p>
<ul>
<li>Remapped to a different device(8,2)</li>
<li>Handled by the request queue code</li>
<li>Back merged with request on queue</li>
</ul>
<p>blkparse output also includes a summary to explain the number of I&#x2F;Os in each queuing phase. In the following example, there are 86 writes handled by request queue. 19 out of 86 writes are merged with request on queue. Thus, only 67 writes are issued to device to complete the front end requests.</p>
<pre><code>Total (sda):
 Reads Queued:           0,        0KiB  Writes Queued:          86,      628KiB
 Read Dispatches:        0,        0KiB  Write Dispatches:       67,      628KiB
 Reads Requeued:         0               Writes Requeued:         0
 Reads Completed:        0,        0KiB  Writes Completed:       67,      628KiB
 Read Merges:            0,        0KiB  Write Merges:           19,       88KiB
 IO unplugs:            21               Timer unplugs:           0
</code></pre>
<h2 id="btt"><a href="#btt" class="headerlink" title="btt"></a>btt</h2><p>btt is a post-processing tool for blktrace. blktrace is capable of producing tremendous amounts of output in the form of multiple individual traces per IO executed during the traced run. It is also capable of producing some general statistics concerning IO rates and the like. btt goes further and produces a variety of overall statistics about each of the individual handling of IOs, and provides data we believe is useful to plot to provide visual comparisons for evaluation.</p>
<p>btt processes the binary file produced by blkparse.The major areas of output measured by btt include:</p>
<ul>
<li>Q2Q : Queue-to-Queue time</li>
<li>Q2G : Queue-to-GetRequest time</li>
<li>S2G : Sleep-to-GetRequest time</li>
<li>G2I : GetRequest-to-Insert time</li>
<li>Q2M : Queue-to-Merge time</li>
<li>I2D : Insert-to-Issue time</li>
<li>M2D : Merge-to-Issue time</li>
<li>D2C : Issue-to-Complete time</li>
<li>Q2C : Queue-to-Complete time</li>
</ul>
<p>For the D2C, it includes the driver and device time. It’s the average time from when the actual IO was issued to the driver until is completed (completion trace) back to the block IO layer. The D2C time should be greater than the actual physcial disk I&#x2F;O latency which is usually measured in disk(array) side.</p>
<p>In the following exampl, 98.9265% of time is spent on D2C which is expected. The average IO time serviced by the disk is 1.65ms. The max IO time is 5.10ms. We may measure the I2D metric for different I&#x2F;O scheduler, like noop in SSD case.</p>
<pre><code>$ btt -i blktrace.bin -B offset -o btt.out

$ ls btt.*.out*
btt.sda.30s.out.avg  btt.sda.30s.out.dat  btt.sda.30s.out_dhist.dat  btt.sda.30s.out.msg  btt.sda.30s.out_qhist.dat

$ cat btt.out.avg
==================== All Devices ====================

ALL               MIN           AVG           MAX                  N
--------------- ------------- ------------- ------------- -----------

Q2Q               0.000001053   0.304967428   5.071043004          85
Q2G               0.000000338   0.000001928   0.000008143          67
G2I               0.000000161   0.000008231   0.000126276          67
Q2M               0.000000178   0.000000664   0.000002175          19
I2D               0.000000223   0.000003979   0.000024517          67
M2D               0.000002771   0.000030058   0.000116136          19
D2C               0.000089761   0.001640496   0.005096214          86
Q2C               0.000093453   0.001658297   0.005098018          86

==================== Device Overhead ====================

       DEV |       Q2G       G2I       Q2M       I2D       D2C
---------- | --------- --------- --------- --------- ---------
 (  8,  0) |   0.0906%   0.3867%   0.0088%   0.1869%  98.9265%
---------- | --------- --------- --------- --------- ---------
   Overall |   0.0906%   0.3867%   0.0088%   0.1869%  98.9265%
[..]   
</code></pre>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.flamingbytes.com/blog/understanding-await-in-iostat/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/logo/FlamingBytes-icon-64x64-1.png">
      <meta itemprop="name" content="relentlesstorm">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FlamingBytes">
      <meta itemprop="description" content="Stay hungry, stay foolish">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | FlamingBytes">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/blog/understanding-await-in-iostat/" class="post-title-link" itemprop="url">Understanding await in iostat</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-03-10 08:00:00" itemprop="dateCreated datePublished" datetime="2021-03-10T08:00:00-08:00">2021-03-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-10-22 11:28:20" itemprop="dateModified" datetime="2023-10-22T11:28:20-07:00">2023-10-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Tech/" itemprop="url" rel="index"><span itemprop="name">Tech</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Tech/Performance/" itemprop="url" rel="index"><span itemprop="name">Performance</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="What’s-meaning-of-await-in-iostat"><a href="#What’s-meaning-of-await-in-iostat" class="headerlink" title="What’s meaning of await in iostat?"></a>What’s meaning of await in iostat?</h2><p>The following is the description provided for await field in iostat man page.</p>
<pre><code>$ man iostat
await
    The average time (in milliseconds) for I/O requests issued to the device to be served. This includes the time spent by the requests in queue and the time spent servicing them.
</code></pre>
<p>It is a measure of disk I&#x2F;O latency in milliseconds. The latency is from the front of the I&#x2F;O scheduler to the I&#x2F;O completion time.</p>
<h2 id="I-O-path"><a href="#I-O-path" class="headerlink" title="I&#x2F;O path"></a>I&#x2F;O path</h2><p>The I&#x2F;O path mainly includes the following footprints from block layer to underneath storage device.</p>
<ul>
<li><p>Get the I&#x2F;O requests from application(filesystem)</p>
</li>
<li><p>Merge the I&#x2F;O requests to existing device queue</p>
</li>
<li><p>Dispatch the I&#x2F;O requests(by the I&#x2F;O scheduler) to the device driver</p>
</li>
<li><p>Hypervisor scheduler in virtualization if any</p>
</li>
<li><p>Multipathing if any</p>
</li>
<li><p>Hardware handling</p>
</li>
<li><p>HBA driver</p>
</li>
<li><p>Transportation(bus)</p>
</li>
<li><p>FC switch routing if any</p>
</li>
<li><p>Storage controller queuing, caching and processing</p>
</li>
<li><p>Actual disk latency</p>
</li>
</ul>
<h2 id="How-the-await-time-is-calculated"><a href="#How-the-await-time-is-calculated" class="headerlink" title="How the await time is calculated?"></a>How the await time is calculated?</h2><p>The await is the average time on a per I&#x2F;O basis, measured in milliseconds. It mainly includes the time spent in I&#x2F;O scheduler queue and time spent on storage servicing it if the HBA&#x2F;SAN latency is relatively marginal.</p>
<p>There are two queues involved in the I&#x2F;O processing path.</p>
<ul>
<li>The queue in I&#x2F;O scheduler</li>
<li>The queue in storage side(e.g. controller)</li>
</ul>
<p><em>nr_requests</em> limits the maximum number of I&#x2F;Os in the sorted request queue. The front thread will be blocked if the I&#x2F;O can’t be merged&#x2F;inserted into the scheduler queue due to the full occupancy of the queue . Note that the <em>nr_requests</em> is applied to read and write separately.</p>
<p>After the I&#x2F;O is passed to the driver, it is no longer in the scheduler queue and doesn’t cout to <em>nr_requests</em> limit. However, it will count to <em>avgqu-sz</em>. So, the <em>avgqu-sz</em> could reach the sum of <em>nr_requests</em> and LUN <em>queue_depth</em>.</p>
<h2 id="How-the-svctm-time-is-measured"><a href="#How-the-svctm-time-is-measured" class="headerlink" title="How the svctm time is measured?"></a>How the svctm time is measured?</h2><p>await measures the I&#x2F;O latency on a per I&#x2F;O basis while svctm take into account parallel I&#x2F;O. For example, if 100 I&#x2F;Os are submitted to the I&#x2F;O scheduler in parallel and queued onto storage(say queue_depth&#x3D;50), and the 100 I&#x2F;Os completes in 10ms, the await time would be 10ms, but the svctm time could be 2ms.</p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>Since await includes the time spent in I&#x2F;O scheduler and storage queue servicing. We may want to see a breakdown for the two parts by using blktrace. It would tell us the overheads on disk queue(I2D) and actual I&#x2F;O service latency(D2C). For furhter study of blktrace, you can read this <a href="!--swig%EF%BF%BC0--">article</a>.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.flamingbytes.com/blog/buffered-and-direct-io/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/logo/FlamingBytes-icon-64x64-1.png">
      <meta itemprop="name" content="relentlesstorm">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FlamingBytes">
      <meta itemprop="description" content="Stay hungry, stay foolish">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | FlamingBytes">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/blog/buffered-and-direct-io/" class="post-title-link" itemprop="url">Buffered and Direct IO</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-03-09 08:00:00" itemprop="dateCreated datePublished" datetime="2021-03-09T08:00:00-08:00">2021-03-09</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-10-22 11:28:20" itemprop="dateModified" datetime="2023-10-22T11:28:20-07:00">2023-10-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Tech/" itemprop="url" rel="index"><span itemprop="name">Tech</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Tech/Performance/" itemprop="url" rel="index"><span itemprop="name">Performance</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="Buffered-and-Direct-I-O"><a href="#Buffered-and-Direct-I-O" class="headerlink" title="Buffered and Direct I&#x2F;O"></a>Buffered and Direct I&#x2F;O</h2><p>The VxFS responds with read-ahead for sequential read I&#x2F;O. This results in buffered I&#x2F;O. The data is prefetched and retained in buffers, in anticipation of application asking for it. The data buffers are commonly referred to as the VxFS buffer cache. This is the default VxFS behavior.</p>
<p>Direct I&#x2F;O, on the other hand, does not buffer the data when the I&#x2F;O to the underlying device is completed. This saves system resources like memory and CPU usage. Direct I&#x2F;O is possible only when alignment and sizing criteria are satisfied.</p>
<p>All the supported platforms have a VxFS buffer cache. Each platform also has either a page cache, (aix&#x2F;solaris&#x2F;linux) or its own buffer cache (HP-UX). These caches are commonly known as the file system caches.</p>
<p>Direct I&#x2F;O does not use these caches. The memory used for direct I&#x2F;O is discarded after the I&#x2F;O is complete, and is therefore not buffered.</p>
<h2 id="Direct-I-O"><a href="#Direct-I-O" class="headerlink" title="Direct I&#x2F;O"></a>Direct I&#x2F;O</h2><p>Direct I&#x2F;O is an unbuffered form of I&#x2F;O. If the VX_DIRECT advisory is set, the user is requesting direct data transfer between the disk and the user-supplied buffer for reads and writes. This bypasses the kernel buffering of data, and reduces the CPU overhead associated with I&#x2F;O by eliminating the data copy between the kernel buffer and the user’s buffer. This also avoids taking up space in the buffer cache that might be better used for something else. The direct I&#x2F;O feature can provide significant performance gains for some applications.</p>
<p>The direct I&#x2F;O and VX_DIRECT advisories are maintained on a per-file-descriptor basis.</p>
<h2 id="Direct-I-O-requirements"><a href="#Direct-I-O-requirements" class="headerlink" title="Direct I&#x2F;O requirements"></a>Direct I&#x2F;O requirements</h2><p>For an I&#x2F;O operation to be performed as direct I&#x2F;O, it must meet certain alignment criteria. The alignment constraints are usually determined by the disk driver, the disk controller, and the system memory management hardware and software.</p>
<p>The requirements for direct I&#x2F;O are as follows:</p>
<p>The starting file offset must be aligned to a 512-byte boundary.</p>
<p>The ending file offset must be aligned to a 512-byte boundary, or the length must be a multiple of 512 bytes.</p>
<p>The memory buffer must start on an 8-byte boundary.</p>
<h2 id="Direct-I-O-vs-synchronous-I-O"><a href="#Direct-I-O-vs-synchronous-I-O" class="headerlink" title="Direct I&#x2F;O vs. synchronous I&#x2F;O"></a>Direct I&#x2F;O vs. synchronous I&#x2F;O</h2><p>Because direct I&#x2F;O maintains the same data integrity as synchronous I&#x2F;O, it can be used in many applications that currently use synchronous I&#x2F;O. If a direct I&#x2F;O request does not allocate storage or extend the file, the inode is not immediately written.</p>
<h2 id="Direct-I-O-CPU-overhead"><a href="#Direct-I-O-CPU-overhead" class="headerlink" title="Direct I&#x2F;O CPU overhead"></a>Direct I&#x2F;O CPU overhead</h2><p>The CPU cost of direct I&#x2F;O is about the same as a raw disk transfer. For sequential I&#x2F;O to very large files, using direct I&#x2F;O with large transfer sizes can provide the same speed as buffered I&#x2F;O with much less CPU overhead.</p>
<p>If the file is being extended or storage is being allocated, direct I&#x2F;O must write the inode change before returning to the application. This eliminates some of the performance advantages of direct I&#x2F;O.</p>
<h2 id="Discovered-Direct-I-O"><a href="#Discovered-Direct-I-O" class="headerlink" title="Discovered Direct I&#x2F;O"></a>Discovered Direct I&#x2F;O</h2><p>Discovered Direct I&#x2F;O is a file system tunable you can set using the vxtunefs command. When the file system gets an I&#x2F;O request larger than the discovered_direct_iosz, it tries to use direct I&#x2F;O on the request. For large I&#x2F;O sizes, Discovered Direct I&#x2F;O can perform much better than buffered I&#x2F;O.</p>
<p>Discovered Direct I&#x2F;O behavior is similar to direct I&#x2F;O and has the same alignment constraints, except writes that allocate storage or extend the file size do not require writing the inode changes before returning to the application.</p>
<h2 id="Unbuffered-I-O"><a href="#Unbuffered-I-O" class="headerlink" title="Unbuffered I&#x2F;O"></a>Unbuffered I&#x2F;O</h2><p>If the VX_UNBUFFERED advisory is set, I&#x2F;O behavior is the same as direct I&#x2F;O with the VX_DIRECT advisory set, so the alignment constraints that apply to direct I&#x2F;O also apply to unbuffered I&#x2F;O. For unbuffered I&#x2F;O, however, if the file is being extended, or storage is being allocated to the file, inode changes are not updated synchronously before the write returns to the user. The VX_UNBUFFERED advisory is maintained on a per-file-descriptor basis.</p>
<p>For information on how to set the discovered_direct_iosz, see Tuning I&#x2F;O.</p>
<h2 id="Data-synchronous-I-O"><a href="#Data-synchronous-I-O" class="headerlink" title="Data synchronous I&#x2F;O"></a>Data synchronous I&#x2F;O</h2><p>If the VX_DSYNC advisory is set, the user is requesting data synchronous I&#x2F;O. In synchronous I&#x2F;O, the data is written, and the inode is written with updated times and (if necessary) an increased file size. In data synchronous I&#x2F;O, the data is transferred to disk synchronously before the write returns to the user. If the file is not extended by the write, the times are updated in memory, and the call returns to the user. If the file is extended by the operation, the inode is written before the write returns.</p>
<p>The direct I&#x2F;O and VX_DSYNC advisories are maintained on a per-file-descriptor basis.</p>
<h2 id="Data-synchronous-I-O-vs-synchronous-I-O"><a href="#Data-synchronous-I-O-vs-synchronous-I-O" class="headerlink" title="Data synchronous I&#x2F;O vs. synchronous I&#x2F;O"></a>Data synchronous I&#x2F;O vs. synchronous I&#x2F;O</h2><p>Like direct I&#x2F;O, the data synchronous I&#x2F;O feature can provide significant application performance gains. Because data synchronous I&#x2F;O maintains the same data integrity as synchronous I&#x2F;O, it can be used in many applications that currently use synchronous I&#x2F;O. If the data synchronous I&#x2F;O does not allocate storage or extend the file, the inode is not immediately written. The data synchronous I&#x2F;O does not have any alignment constraints, so applications that find it difficult to meet the alignment constraints of direct I&#x2F;O should use data synchronous I&#x2F;O.</p>
<p>If the file is being extended or storage is allocated, data synchronous I&#x2F;O must write the inode change before returning to the application. This case eliminates the performance advantage of data synchronous I&#x2F;O.</p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul>
<li><a target="_blank" rel="noopener" href="https://sort.veritas.com/public/documents/sf/5.0/aix/html/fs_admin/ag_ch_interface_fs4.html">https://sort.veritas.com/public/documents/sf/5.0/aix/html/fs_admin&#x2F;ag_ch_interface_fs4.html</a></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.flamingbytes.com/blog/network-ring-buffer/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/logo/FlamingBytes-icon-64x64-1.png">
      <meta itemprop="name" content="relentlesstorm">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FlamingBytes">
      <meta itemprop="description" content="Stay hungry, stay foolish">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | FlamingBytes">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/blog/network-ring-buffer/" class="post-title-link" itemprop="url">Network ring buffer</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-03-04 08:00:00" itemprop="dateCreated datePublished" datetime="2021-03-04T08:00:00-08:00">2021-03-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-10-22 11:28:20" itemprop="dateModified" datetime="2023-10-22T11:28:20-07:00">2023-10-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Tech/" itemprop="url" rel="index"><span itemprop="name">Tech</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Tech/Linux/" itemprop="url" rel="index"><span itemprop="name">Linux</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Receive ring buffers are shared between the device driver and NIC. The card assigns a transmit (TX) and receive (RX) ring buffer. As the name implies, the ring buffer is a circular buffer where an overflow simply overwrites existing data. It should be noted that there are two ways to move data from the NIC to the kernel, hardware interrupts and software interrupts, also called SoftIRQs.</p>
<p>The RX ring buffer is used to store incoming packets until they can be processed by the device driver. The device driver drains the RX ring, typically via SoftIRQs, which puts the incoming packets into a kernel data structure called an sk_buff or “skb” to begin its journey through the kernel and up to the application which owns the relevant socket. The TX ring buffer is used to hold outgoing packets which are destined for the wire.</p>
<p>These ring buffers reside at the bottom of the stack and are a crucial point at which packet drop can occur, which in turn will adversely affect network performance.</p>
<p>You can increase the size of the Ethernet device RX ring buffer if the packet drop rate causes applications to report:</p>
<ul>
<li>a loss of data</li>
<li>cluster fence</li>
<li>slow performance</li>
<li>timeouts</li>
<li>failed backups</li>
</ul>
<h2 id="Interrupts-and-Interrupt-Handlers"><a href="#Interrupts-and-Interrupt-Handlers" class="headerlink" title="Interrupts and Interrupt Handlers"></a>Interrupts and Interrupt Handlers</h2><p>Interrupts from the hardware are known as “top-half” interrupts. When a NIC receives incoming data, it copies the data into kernel buffers using DMA. The NIC notifies the kernel of this data by raising a hard interrupt. These interrupts are processed by interrupt handlers which do minimal work, as they have already interrupted another task and cannot be interrupted themselves. Hard interrupts can be expensive in terms of CPU usage, especially when holding kernel locks. The hard interrupt handler then leaves the majority of packet reception to a software interrupt, or SoftIRQ, process which can be scheduled more fairly.</p>
<p>Hard interrupts can be seen in &#x2F;proc&#x2F;interrupts where each queue has an interrupt vector in the 1st column assigned to it. These are initialized when the system boots or when the NIC device driver module is loaded. Each RX and TX queue is assigned a unique vector, which informs the interrupt handler as to which NIC&#x2F;queue the interrupt is coming from. The columns represent the number of incoming interrupts as a counter value:</p>
<pre><code>$ egrep “CPU0|eth2” /proc/interrupts
 CPU0 CPU1 CPU2 CPU3 CPU4 CPU5
 105: 141606 0 0 0 0 0 IR-PCI-MSI-edge eth2-rx-0
 106: 0 141091 0 0 0 0 IR-PCI-MSI-edge eth2-rx-1
 107: 2 0 163785 0 0 0 IR-PCI-MSI-edge eth2-rx-2
 108: 3 0 0 194370 0 0 IR-PCI-MSI-edge eth2-rx-3
 109: 0 0 0 0 0 0 IR-PCI-MSI-edge eth2-tx
</code></pre>
<h2 id="SoftIRQs"><a href="#SoftIRQs" class="headerlink" title="SoftIRQs"></a>SoftIRQs</h2><p>Also known as “bottom-half” interrupts, software interrupt requests (SoftIRQs) are kernel routines which are scheduled to run at a time when other tasks will not be interrupted. The SoftIRQ’s purpose is to drain the network adapter receive ring buffers. These routines run in the form of ksoftirqd&#x2F;cpu-number processes and call driver-specific code functions. They can be seen in process monitoring tools such as ps and top.</p>
<p>The following call stack, read from the bottom up, is an example of a SoftIRQ polling a Mellanox card. The functions marked [mlx4_en] are the Mellanox polling routines in the mlx4_en.ko driver kernel module, called by the kernel’s generic polling routines such as net_rx_action. After moving from the driver to the kernel, the traffic being received will then move up to the socket, ready for the application to consume:</p>
<pre><code> mlx4_en_complete_rx_desc [mlx4_en]
 mlx4_en_process_rx_cq [mlx4_en]
 mlx4_en_poll_rx_cq [mlx4_en]
 net_rx_action
 __do_softirq
 run_ksoftirqd
 smpboot_thread_fn
 kthread
 kernel_thread_starter
 kernel_thread_starter
 1 lock held by ksoftirqd
</code></pre>
<p>SoftIRQs can be monitored as follows. Each column represents a CPU:</p>
<pre><code>$ watch -n1 grep RX /proc/softirqs
$ watch -n1 grep TX /proc/softirqs
</code></pre>
<h2 id="Displaying-the-number-of-dropped-packets"><a href="#Displaying-the-number-of-dropped-packets" class="headerlink" title="Displaying the number of dropped packets"></a>Displaying the number of dropped packets</h2><p>The ethtool utility enables administrators to query, configure, or control network driver settings.</p>
<p>The exhaustion of the RX ring buffer causes an increment in the counters, such as “discard” or “drop” in the output of ethtool -S interface_name. The discarded packets indicate that the available buffer is filling up faster than the kernel can process the packets.</p>
<p>To display drop counters for the enp1s0 interface, enter:</p>
<pre><code>$ ethtool -S enp1s0
</code></pre>
<h2 id="Increasing-the-RX-ring-buffer-to-reduce-a-high-packet-drop-rate"><a href="#Increasing-the-RX-ring-buffer-to-reduce-a-high-packet-drop-rate" class="headerlink" title="Increasing the RX ring buffer to reduce a high packet drop rate"></a>Increasing the RX ring buffer to reduce a high packet drop rate</h2><p>The ethtool utility helps to increase the RX buffer to reduce a high packet drop rate.</p>
<ol>
<li><p>To view the maximum RX ring buffer size:</p>
<p> $ ethtool -g nic0<br> Ring parameters for nic0:<br> Pre-set maximums:<br> RX:             4078<br> RX Mini:        0<br> RX Jumbo:       0<br> TX:             4078<br> Current hardware settings:<br> RX:             2048<br> RX Mini:        0<br> RX Jumbo:       0<br> TX:             2048</p>
</li>
<li><p>If the values in the Pre-set maximums section are higher than in the Current hardware settings section, increase RX ring buffer:</p>
</li>
</ol>
<ul>
<li><p>To temporary change the RX ring buffer of the nic0 device to 4078, enter:</p>
<p>  $ ethtool -G nic0 rx 4078</p>
</li>
<li><p>To permanently change the RX ring buffer create a NetworkManager dispatcher script.</p>
</li>
</ul>
<h2 id="Understanding-the-maximum-RX-TX-ring-buffer"><a href="#Understanding-the-maximum-RX-TX-ring-buffer" class="headerlink" title="Understanding the maximum RX&#x2F;TX ring buffer"></a>Understanding the maximum RX&#x2F;TX ring buffer</h2><p>From <a target="_blank" rel="noopener" href="https://elixir.bootlin.com/linux/latest/source/include/linux/ethtool.h">ethtool</a> source code, we can find the following function which is used by command “ethtool -g [nic]”</p>
<pre><code>* @get_ringparam: Report ring sizes
</code></pre>
<p>For different NIC vender, the <a target="_blank" rel="noopener" href="https://elixir.bootlin.com/linux/latest/C/ident/get_ringparam">driver</a> may be implemented differently.</p>
<p>In this example, the NIC driver is bnx2x.</p>
<pre><code>$ ethtool -i nic0
driver: bnx2x
</code></pre>
<p>So, we can check the <a target="_blank" rel="noopener" href="https://elixir.bootlin.com/linux/latest/source/drivers/net/ethernet/broadcom/bnx2x/bnx2x_ethtool.c#L3677">source code</a> as below.</p>
<pre><code>static void bnx2x_get_ringparam(struct net_device *dev,
                struct ethtool_ringparam *ering)
&#123;
    struct bnx2x *bp = netdev_priv(dev);

    ering-&gt;rx_max_pending = MAX_RX_AVAIL;

    /* If size isn&#39;t already set, we give an estimation of the number
     * of buffers we&#39;ll have. We&#39;re neglecting some possible conditions
     * [we couldn&#39;t know for certain at this point if number of queues
     * might shrink] but the number would be correct for the likely
     * scenario.
     */
    if (bp-&gt;rx_ring_size)
        ering-&gt;rx_pending = bp-&gt;rx_ring_size;
    else if (BNX2X_NUM_RX_QUEUES(bp))
        ering-&gt;rx_pending = MAX_RX_AVAIL / BNX2X_NUM_RX_QUEUES(bp);
    else
        ering-&gt;rx_pending = MAX_RX_AVAIL;

    ering-&gt;tx_max_pending = IS_MF_FCOE_AFEX(bp) ? 0 : MAX_TX_AVAIL;
    ering-&gt;tx_pending = bp-&gt;tx_ring_size;
&#125;
</code></pre>
<p>MAX_RX_AVAIL is the place to define the maximum RX ring buffer. We can further check the formula as below.</p>
<pre><code>#define MAX_RX_AVAIL		(MAX_RX_DESC_CNT * NUM_RX_RINGS - 2)

#define NUM_RX_RINGS		8

#define MAX_RX_DESC_CNT		(RX_DESC_CNT - NEXT_PAGE_RX_DESC_CNT)
#define RX_DESC_CNT		(BCM_PAGE_SIZE / sizeof(struct eth_rx_bd))
#define NEXT_PAGE_RX_DESC_CNT	2

#define BCM_PAGE_SIZE		(1 &lt;&lt; BCM_PAGE_SHIFT)
#define BCM_PAGE_SHIFT		12

/*
 * The eth Rx Buffer Descriptor
 */
struct eth_rx_bd &#123;
    __le32 addr_lo;
    __le32 addr_hi;
&#125;;
</code></pre>
<p>So, based on the formula above, we can calculate the maximum RX ring buffer as below.</p>
<pre><code>rx_max = MAX_RX_AVAIL 
       = MAX_RX_DESC_CNT * NUM_RX_RINGS - 2
       = (RX_DESC_CNT - NEXT_PAGE_RX_DESC_CNT) * NUM_RX_RINGS - 2
       = ((BCM_PAGE_SIZE / sizeof(struct eth_rx_bd)) - 2) * 8 - 2
       = (((1 &lt;&lt; BCM_PAGE_SHIFT) / sizeof(struct eth_rx_bd)) - 2) * 8 - 2
       = ((4096 / 8 ) - 2) * 8 - 2
       = 4078
</code></pre>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul>
<li><a target="_blank" rel="noopener" href="https://access.redhat.com/sites/default/files/attachments/20150325_network_performance_tuning.pdf">Red Hat Enterprise Linux Network Performance Tuning Guide</a></li>
<li><a target="_blank" rel="noopener" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/configuring_and_managing_networking/monitoring-and-tuning-the-rx-ring-buffer_configuring-and-managing-networking">MONITORING AND TUNING THE RX RING BUFFER</a></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.flamingbytes.com/blog/semaphore/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/logo/FlamingBytes-icon-64x64-1.png">
      <meta itemprop="name" content="relentlesstorm">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FlamingBytes">
      <meta itemprop="description" content="Stay hungry, stay foolish">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | FlamingBytes">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/blog/semaphore/" class="post-title-link" itemprop="url">Semaphore</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-03-03 08:00:00" itemprop="dateCreated datePublished" datetime="2021-03-03T08:00:00-08:00">2021-03-03</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-10-22 11:28:20" itemprop="dateModified" datetime="2023-10-22T11:28:20-07:00">2023-10-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Tech/" itemprop="url" rel="index"><span itemprop="name">Tech</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Tech/Linux/" itemprop="url" rel="index"><span itemprop="name">Linux</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="What-is-semaphore"><a href="#What-is-semaphore" class="headerlink" title="What is semaphore"></a>What is semaphore</h2><p>A semaphore is a very relaxed type of lockable object. A given semaphore has a predefined maximum count, and a current count. You take ownership of a semaphore with a wait operation, also referred to as decrementing the semaphore, or even just abstractly called P. You release ownership with a signal operation, also referred to as incrementing the semaphore, a post operation, or abstractly called V. The single-letter operation names are from Dijkstra’s original paper on semaphores.</p>
<p>Every time you wait on a semaphore, you decrease the current count. If the count was greater than zero then the decrement just happens, and the wait call returns. If the count was already zero then it cannot be decremented, so the wait call will block until another thread increases the count by signaling the semaphore.</p>
<h2 id="Semaphore-tuning"><a href="#Semaphore-tuning" class="headerlink" title="Semaphore tuning"></a>Semaphore tuning</h2><p>To display the semaphore limits:</p>
<pre><code>$ cat /proc/sys/kernel/sem
300	307200	32	1024

$ sysctl -a | grep sem
kernel.sem = 300	307200	32	1024

$ ipcs -l | grep -i &quot;sem&quot;
------ Semaphore Limits --------
max semaphores per array = 300
max semaphores system wide = 307200
max ops per semop call = 32
semaphore max value = 32767
</code></pre>
<p>The values of the semaphore parameters are displayed in the following order.</p>
<ul>
<li>SEMMSL - The maximum number of semaphores in a sempahore set.</li>
<li>SEMMNS - A system-wide limit on the number of semaphores in all semaphore sets. The maximum number of sempahores in the system.</li>
<li>SEMOPM - The maximum number of operations in a single semop call</li>
<li>SEMMNI - A system-wide limit on the maximum number of semaphore identifiers (sempahore sets)</li>
</ul>
<p>To display the current semaphore status:</p>
<pre><code>$ ipcs -u | egrep -i &quot;used arrays|sem&quot;
------ Semaphore Status --------
used arrays = 3
allocated semaphores = 3
</code></pre>
<p>To display the active semaphore sets info:</p>
<pre><code>$ ipcs -s
------ Semaphore Arrays --------
key        semid      owner      perms      nsems
0x00000000 0          root       600        1
0x00000000 32769      root       600        1
0x00005653 229380     root       666        1
</code></pre>
<p>To adjust the semaphore values on the fly:</p>
<pre><code>$ echo 300   307200   32   1024 &gt; /proc/sys/kernel/sem
</code></pre>
<p>To modify system semaphore values permanently:</p>
<pre><code>$ echo &quot;kernel.sem = 300  307200  32  1024&quot; &gt;&gt; /etc/sysctl.conf
$ sysctl -p 
</code></pre>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.flamingbytes.com/blog/max-open-files-limit/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/logo/FlamingBytes-icon-64x64-1.png">
      <meta itemprop="name" content="relentlesstorm">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FlamingBytes">
      <meta itemprop="description" content="Stay hungry, stay foolish">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | FlamingBytes">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/blog/max-open-files-limit/" class="post-title-link" itemprop="url">Max open files limit</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-03-02 08:00:00" itemprop="dateCreated datePublished" datetime="2021-03-02T08:00:00-08:00">2021-03-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-10-22 11:28:20" itemprop="dateModified" datetime="2023-10-22T11:28:20-07:00">2023-10-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Tech/" itemprop="url" rel="index"><span itemprop="name">Tech</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Tech/Linux/" itemprop="url" rel="index"><span itemprop="name">Linux</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="System-wide-open-files-limit"><a href="#System-wide-open-files-limit" class="headerlink" title="System wide open files limit"></a>System wide open files limit</h2><p>To check system wide files limit:</p>
<pre><code>$ cat /proc/sys/fs/file-max
4875932
$ sysctl -a | grep file-max
fs.file-max = 4875932
</code></pre>
<p>To change system wide files limit:</p>
<pre><code>$ echo &quot;fs.file-max = 4875932&quot; &gt;&gt; /etc/sysctl.conf
$ sysctl -p /etc/sysctl.conf
</code></pre>
<h2 id="User-level-open-files-limit"><a href="#User-level-open-files-limit" class="headerlink" title="User level open files limit"></a>User level open files limit</h2><p>To check hard&#x2F;soft limits:</p>
<pre><code>$ ulimit -Hn
40960
$ ulimit -Sn
40960
</code></pre>
<p>To change hard&#x2F;soft limits:</p>
<pre><code>$ vi /etc/security/limits.conf
*  hard nofile 40960
*  soft nofile 40960
</code></pre>
<h2 id="Process-level-open-files-limit"><a href="#Process-level-open-files-limit" class="headerlink" title="Process level open files limit"></a>Process level open files limit</h2><p>To check the max open files per process:</p>
<pre><code>$ cat /proc/sys/fs/nr_open
1048576
</code></pre>
<p>To check the specific process max open files limit:</p>
<pre><code>$ cat /proc/`pidof &lt;process-name&gt;`/limits | egrep &quot;Limit |Max open files&quot;
Limit                     Soft Limit           Hard Limit           Units
Max open files            524352               524352               files
</code></pre>
<p>Sometimes, application process may need change the max open files limits on the fly.</p>
<p>In Docker container, the process does not have the permission to do so by default.</p>
<p>Docker provides the following two ways to extend Linux capabilities for the container processes.</p>
<ul>
<li>–cap-add	    Add Linux capabilities</li>
<li>–cap-drop	Drop Linux capabilities</li>
<li>–privileged	Give extended privileges to this container</li>
</ul>
<p>When using the “–privileged” option is not allowed for security reason, we can have fine grain control over the capabilities using –cap-add and –cap-drop.</p>
<p>For example, if we want to grant the container process the permission to change max open files limit on the fly, we can use the following capability option.</p>
<ul>
<li>SYS_RESOURCE - Override resource Limits.</li>
</ul>
<p>We can pass this option to the target docker container.</p>
<pre><code>$ docker run --cap-add=SYS_ADMIN ...
</code></pre>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul>
<li><a target="_blank" rel="noopener" href="https://docs.docker.com/engine/reference/run/">https://docs.docker.com/engine/reference/run/</a></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.flamingbytes.com/blog/iozone-a-filesystem-benchmark-tool/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/logo/FlamingBytes-icon-64x64-1.png">
      <meta itemprop="name" content="relentlesstorm">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FlamingBytes">
      <meta itemprop="description" content="Stay hungry, stay foolish">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | FlamingBytes">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/blog/iozone-a-filesystem-benchmark-tool/" class="post-title-link" itemprop="url">Iozone - A filesystem benchmark tool</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-03-01 08:00:00" itemprop="dateCreated datePublished" datetime="2021-03-01T08:00:00-08:00">2021-03-01</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-11-01 21:30:30" itemprop="dateModified" datetime="2023-11-01T21:30:30-07:00">2023-11-01</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Tech/" itemprop="url" rel="index"><span itemprop="name">Tech</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Tech/Benchmarking/" itemprop="url" rel="index"><span itemprop="name">Benchmarking</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p><a target="_blank" rel="noopener" href="https://www.iozone.org/">IOzone</a> is a filesystem benchmark tool. The benchmark generates and measures a variety of file operations.</p>
<p>Iozone is useful for performing a broad filesystem analysis of a vendor’s computer platform. The benchmark tests file I&#x2F;O performance for the following operations:</p>
<ul>
<li>Read, write, re-read, re-write, read backwards, read strided, fread, fwrite, random read, pread ,mmap, aio_read, aio_write</li>
</ul>
<h2 id="Example-for-throughput-benchmark"><a href="#Example-for-throughput-benchmark" class="headerlink" title="Example for throughput benchmark"></a>Example for throughput benchmark</h2><p>In this example, the target is to measure the filesystem throughput(KB&#x2F;s) for different workloads with 4k iosize. The workload operations include sequential read&#x2F;write, random read&#x2F;write and mix random read&#x2F;write.</p>
<p>We run iozone on 6 mounted filesystems and 1GB files are read and written in each filesystem.</p>
<pre><code class="bash">$ /opt/iozone/bin/iozone -h
    -r #  record size in Kb
    -s #  file size in Kb
    -t #  Number of threads or processes to use in throughput test
    -I  Use VxFS VX_DIRECT, O_DIRECT,or O_DIRECTIO for all file operations    
    -F filenames  for each process/thread in throughput test
    -i #  Test to run (0=write/rewrite, 1=read/re-read, 2=random-read/write
        3=Read-backwards, 4=Re-write-record, 5=stride-read, 6=fwrite/re-fwrite
        7=fread/Re-fread, 8=random_mix, 9=pwrite/Re-pwrite, 10=pread/Re-pread
        11=pwritev/Re-pwritev, 12=preadv/Re-preadv)
    [...]    

$ /opt/iozone/bin/iozone -i 0 -i 1 -i 2 -i 8 -r 4k -s 1g -t 6 -I -F /testmnt1/testfile1 /testmnt2/testfile1 /testmnt3/testfile1 /testmnt4/testfile1 /testmnt5testfile1 /testmnt6/testfile1 &gt; iozone.out

$ cat iozone.out
Iozone: Performance Test of File I/O
        Version $Revision: 3.489 $
    Compiled for 64 bit mode.
    Build: linux-AMD64
Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins
             Al Slater, Scott Rhine, Mike Wisner, Ken Goss
             Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,
             Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,
             Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,
             Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,
             Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer,
             Vangel Bojaxhi, Ben England, Vikentsi Lapa,
             Alexey Skidanov, Sudhir Kumar.
Run began: Mon Mar  1 12:25:11 2021
Record Size 4 kB
File size set to 1048576 kB
O_DIRECT feature enabled
Command line used: /opt/iozone/bin/iozone -i 0 -i 1 -i 2 -i 8 -r 4k -s 1g -t 6 -I -F /testmnt1/testfile1 /testmnt2/testfile1 /testmnt3/testfile1 /testmnt4testfile1 /testmnt5/testfile1 /testmnt6/testfile1
Output is in kBytes/sec
Time Resolution = 0.000001 seconds.
Processor cache size set to 1024 kBytes.
Processor cache line size set to 32 bytes.
File stride size set to 17 * record size.
Throughput test with 6 processes
Each process writes a 1048576 kByte file in 4 kByte records
Children see throughput for  6 initial writers 	=  151721.80 kB/sec
Parent sees throughput for  6 initial writers 	=  146366.56 kB/sec
Min throughput per process 			=   24712.40 kB/sec
Max throughput per process 			=   25707.35 kB/sec
Avg throughput per process 			=   25286.97 kB/sec
Min xfer 					= 1007996.00 kB
Children see throughput for  6 rewriters 	=  152089.88 kB/sec
Parent sees throughput for  6 rewriters 	=  152084.55 kB/sec
Min throughput per process 			=   25109.69 kB/sec
Max throughput per process 			=   25674.81 kB/sec
Avg throughput per process 			=   25348.31 kB/sec
Min xfer 					= 1025500.00 kB
Children see throughput for  6 readers 		=    7618.06 kB/sec
Parent sees throughput for  6 readers 		=    7618.04 kB/sec
Min throughput per process 			=    1268.31 kB/sec
Max throughput per process 			=    1270.73 kB/sec
Avg throughput per process 			=    1269.68 kB/sec
Min xfer 					= 1046580.00 kB
Children see throughput for 6 re-readers 	=    7629.77 kB/sec
Parent sees throughput for 6 re-readers 	=    7629.74 kB/sec
Min throughput per process 			=    1270.79 kB/sec
Max throughput per process 			=    1273.63 kB/sec
Avg throughput per process 			=    1271.63 kB/sec
Min xfer 					= 1046240.00 kB
Children see throughput for 6 random readers 	=    7605.91 kB/sec
Parent sees throughput for 6 random readers 	=    7605.89 kB/sec
Min throughput per process 			=    1266.91 kB/sec
Max throughput per process 			=    1268.54 kB/sec
Avg throughput per process 			=    1267.65 kB/sec
Min xfer 					= 1047228.00 kB
Children see throughput for 6 mixed workload 	=   79687.92 kB/sec
Parent sees throughput for 6 mixed workload 	=   78974.22 kB/sec
Min throughput per process 			=    1275.41 kB/sec
Max throughput per process 			=   25449.38 kB/sec
Avg throughput per process 			=   13281.32 kB/sec
Min xfer 					=   52552.00 kB
Children see throughput for 6 random writers 	=  146210.38 kB/sec
Parent sees throughput for 6 random writers 	=  143822.17 kB/sec
Min throughput per process 			=   24206.99 kB/sec
Max throughput per process 			=   24653.06 kB/sec
Avg throughput per process 			=   24368.40 kB/sec
Min xfer 					= 1029604.00 kB
iozone test complete.   
</code></pre>
<h2 id="iostat"><a href="#iostat" class="headerlink" title="iostat"></a>iostat</h2><p>In the above test, we use a flash array with single 500TB LUN created. There are 4 active paths from host to the single LUN. Six logical volumes and filesystems are created on the single LUN.</p>
<p>The following is a piece of iostat output for one of the four disks(paths) when the mix random read&#x2F;write workload is running. The read throughput is ~940KB&#x2F;s and the write throughput is 19MB&#x2F;s.</p>
<p>To measure the maximum throughput, we need keep increasing the number of read&#x2F;write threads until the throughput(KB&#x2F;s) is capped. Also, the iosize has big impact on the throughput. We may test with different I&#x2F;O sizes.</p>
<pre><code class="bash">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util
sdd               0.00     0.00  189.80 4255.20   759.20 17020.80     8.00     1.13    0.25    3.07    0.13   0.18  81.80
sdd               0.00     0.00  237.20 4708.20   948.80 18832.80     8.00     1.35    0.27    3.08    0.13   0.20  96.94
sdd               0.00     0.00  235.40 4898.20   941.60 19592.80     8.00     1.37    0.27    3.06    0.13   0.19  99.54
sdd               0.00     0.00  229.60 4575.60   918.40 18302.40     8.00     1.32    0.27    3.09    0.13   0.20  94.28
sdd               0.00     0.00  229.94 4822.55   919.76 19290.22     8.00     1.32    0.26    3.06    0.13   0.19  96.89
sdd               0.00     0.00  228.80 4512.40   915.20 18049.60     8.00     1.30    0.27    3.07    0.13   0.20  94.40
sdd               0.00     0.00  234.20 4810.20   936.80 19240.80     8.00     1.33    0.26    3.08    0.13   0.19  97.10
sdd               0.00     0.00  246.60 4497.40   986.40 17989.60     8.00     1.35    0.28    3.06    0.13   0.20  97.04
sdd               0.00     0.00  106.60 1665.60   426.40  6661.70     8.00     0.55    0.31    3.05    0.14   0.22  38.26
</code></pre>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul>
<li><a target="_blank" rel="noopener" href="https://www.iozone.org/">https://www.iozone.org/</a></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.flamingbytes.com/blog/kubernetes-and-gluster-performance/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/logo/FlamingBytes-icon-64x64-1.png">
      <meta itemprop="name" content="relentlesstorm">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FlamingBytes">
      <meta itemprop="description" content="Stay hungry, stay foolish">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | FlamingBytes">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/blog/kubernetes-and-gluster-performance/" class="post-title-link" itemprop="url">Kubernetes and Gluster performance</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-02-28 08:00:00" itemprop="dateCreated datePublished" datetime="2021-02-28T08:00:00-08:00">2021-02-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-10-22 11:28:20" itemprop="dateModified" datetime="2023-10-22T11:28:20-07:00">2023-10-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Tech/" itemprop="url" rel="index"><span itemprop="name">Tech</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Tech/Performance/" itemprop="url" rel="index"><span itemprop="name">Performance</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="Kubernetes-and-Gluster-Intro"><a href="#Kubernetes-and-Gluster-Intro" class="headerlink" title="Kubernetes and Gluster Intro"></a>Kubernetes and Gluster Intro</h2><p><a target="_blank" rel="noopener" href="https://kubernetes.io/">Kubernetes</a>, also known as K8s, is an open-source system for automating deployment, scaling, and management of containerized applications.</p>
<p><a target="_blank" rel="noopener" href="https://docs.gluster.org/en/latest/Administrator-Guide/GlusterFS-Introduction/">Gluster</a> is a scalable, distributed file system that aggregates disk storage resources from multiple servers into a single global namespace.</p>
<h2 id="Gluster-performance-study"><a href="#Gluster-performance-study" class="headerlink" title="Gluster performance study"></a>Gluster performance study</h2><p>In this article, we will discuss the Gluster performance in a Docker container environment which is built on Kubernetes.</p>
<h3 id="Configuration"><a href="#Configuration" class="headerlink" title="Configuration"></a>Configuration</h3><p>We use three Redhat Linux servers to form a Kubernetes cluster in this study. A Kubernetes cluster that handles production traffic should have a minimum of three nodes.</p>
<p>We have three Docker containers(application instances) provisioned within the Kubernetes cluster. Each container instance has its own Gluster storage pool.</p>
<pre><code>[node1:root]~&gt; kubectl get services
NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
kubernetes   ClusterIP   10.96.0.1    &lt;none&gt;        443/TCP   6d14h
 
[node1:root]~&gt; kubectl get nodes
NAME    STATUS   ROLES    AGE     VERSION
node1   Ready    master   6d14h   v1.19.3
node2   Ready    master   6d14h   v1.19.3
node3   Ready    master   6d14h   v1.19.3
 
[node1:root]~&gt; kubectl get pods --namespace ns-1
NAME         READY   STATUS    RESTARTS   AGE
container1   1/1     Running   0          6d14h
container2   1/1     Running   0          6d14h
container3   1/1     Running   0          6d14h
[...]
 
[node1:root]~&gt; gluster pool list
UUID                    Hostname    State
45d8ec04-4e7a-4442-bbb4-557256b864d6    10.10.1.3 Connected
875be270-ae69-45ea-b38e-2768b7c6ce05    10.10.1.4 Connected
f2696790-b305-4099-8dba-b31d23b0beac    localhost Connected
</code></pre>
<h3 id="Workload-and-performance"><a href="#Workload-and-performance" class="headerlink" title="Workload and performance"></a>Workload and performance</h3><p>We keep increasing the number of workload processes across three container instances and measure the throughput in MB&#x2F;s. For each workload process, it ingests data from multiple clients through 10GbE bonding network and writes the data to the mounted Gluster filesystem.</p>
<p>There are two kinds of workloads. One is very I&#x2F;O intensive and the other is CPU bound.</p>
<p><img src="/images/gluster-perf.png"></p>
<h3 id="Observation"><a href="#Observation" class="headerlink" title="Observation"></a>Observation</h3><ul>
<li>For the CPU bound workload, the performance scales very well.</li>
<li>For the I&#x2F;O bound workload, the performance does not scale when the number of workload processes increases.</li>
</ul>
<h3 id="Analysis"><a href="#Analysis" class="headerlink" title="Analysis"></a>Analysis</h3><p>As we increase the number of workload processes, the workload can be distributed evenly across three instances(on three nodes). Thus, the CPU bandwidth from three nodes are available for the application computing.</p>
<p>Although the storage from three nodes are usable for three container instances, with the default disk allocation for Gluster filesystem, the I&#x2F;O performance may not be optimal. It depends on how the disks are allocated to each Gluster filesystem bricks and how the bricks are assigned to the Gluster filesystems. Also, writing to remote disk would have worse performance due to network latency.</p>
<p>The following is the disk mapping to bricks which are used by one of the three Gluster filesystems. It shows four bricks are created on the same disk <em>&#x2F;dev&#x2F;sde</em> on the node 10.10.1.4. Obviously, the I&#x2F;O performance could be degraded if multiple processes write on it.</p>
<pre><code>brickSize(GB)	device	node
3200	/dev/sdd	10.10.1.2
3200	/dev/sde	10.10.1.2
3200	/dev/sdd	10.10.1.2
3200	/dev/sdd	10.10.1.2
3200	/dev/sdc	10.10.1.3
3200	/dev/sdc	10.10.1.3
3200	/dev/sdb	10.10.1.3
3200	/dev/sdb	10.10.1.3
3200	/dev/sde	10.10.1.4
3200	/dev/sde	10.10.1.4
3200	/dev/sde	10.10.1.4
3200	/dev/sde	10.10.1.4
</code></pre>
<h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>From this case study, we had basic understanding on how the Gluster file system works with storage across multiple nodes. The default Gluster filesystem layout is not fit for all use cases. A custom storage layout would be needed to meet the performance requirement.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.flamingbytes.com/blog/glusterfs-a-distributed-file-syste/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/logo/FlamingBytes-icon-64x64-1.png">
      <meta itemprop="name" content="relentlesstorm">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FlamingBytes">
      <meta itemprop="description" content="Stay hungry, stay foolish">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | FlamingBytes">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/blog/glusterfs-a-distributed-file-syste/" class="post-title-link" itemprop="url">GlusterFS - A distributed file syste</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-02-27 08:00:00" itemprop="dateCreated datePublished" datetime="2021-02-27T08:00:00-08:00">2021-02-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-10-22 11:28:20" itemprop="dateModified" datetime="2023-10-22T11:28:20-07:00">2023-10-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Tech/" itemprop="url" rel="index"><span itemprop="name">Tech</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Tech/Cloud-Storage/" itemprop="url" rel="index"><span itemprop="name">Cloud Storage</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="What-is-Gluster"><a href="#What-is-Gluster" class="headerlink" title="What is Gluster?"></a>What is Gluster?</h2><p><a target="_blank" rel="noopener" href="https://docs.gluster.org/en/latest/Administrator-Guide/GlusterFS-Introduction/">Gluster</a> is a scalable, distributed file system that aggregates disk storage resources from multiple servers into a single global namespace.</p>
<p>Advantages</p>
<ul>
<li>Scales to several petabytes</li>
<li>Handles thousands of clients</li>
<li>POSIX compatible</li>
<li>Uses commodity hardware</li>
<li>Can use any ondisk filesystem that supports extended attributes</li>
<li>Accessible using industry standard protocols like NFS and SMB</li>
<li>Provides replication, quotas, geo-replication, snapshots and bitrot detection</li>
<li>Allows optimization for different workloads</li>
<li>Open Source</li>
</ul>
<h2 id="Installation-and-configuration"><a href="#Installation-and-configuration" class="headerlink" title="Installation and configuration"></a>Installation and configuration</h2><ol>
<li><p>To install gluster and start gluster service:</p>
<p> [root@centos83-1 ~]# cat &#x2F;etc&#x2F;centos-release<br> CentOS Linux release 8.3.2011</p>
<p> [root@centos83-1 ~]# systemctl stop firewalld<br> [root@centos83-1 ~]# systemctl disable firewalld</p>
<p> [root@centos83-1 ~]# yum install -y centos-release-gluster<br> [root@centos83-1 ~]# yum install -y glusterfs-server<br> [root@centos83-1 ~]# rpm -qa |grep gluster<br> glusterfs-cli-8.3-1.el8.x86_64<br> libvirt-daemon-driver-storage-gluster-6.0.0-28.module_el8.3.0+555+a55c8938.x86_64<br> glusterfs-client-xlators-8.3-1.el8.x86_64<br> qemu-kvm-block-gluster-4.2.0-34.module_el8.3.0+555+a55c8938.x86_64<br> libglusterd0-8.3-1.el8.x86_64<br> glusterfs-8.3-1.el8.x86_64<br> pcp-pmda-gluster-5.1.1-3.el8.x86_64<br> glusterfs-fuse-8.3-1.el8.x86_64<br> centos-release-gluster8-1.0-1.el8.noarch<br> libglusterfs0-8.3-1.el8.x86_64<br> glusterfs-server-8.3-1.el8.x86_64</p>
<p> [root@centos83-1 ~]# systemctl enable glusterd<br> [root@centos83-1 ~]# systemctl restart glusterd</p>
<p> [root@centos83-1 ~]# systemctl status glusterd<br>  glusterd.service - GlusterFS, a clustered file-system server<br>  Loaded: loaded (&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;glusterd.service; enabled; vendor preset: enabled)<br>  Active: active (running) since Tue 2021-01-05 17:28:42 PST; 1 months 22 days ago<br>   Docs: man:glusterd(8)<br>  Main PID: 1420 (glusterd)<br>  Tasks: 26 (limit: 409792)<br>  Memory: 152.3M<br>  CGroup: &#x2F;system.slice&#x2F;glusterd.service</p>
</li>
<li><p>To form a trusted storage pool with the second server:</p>
<p> [root@centos83-1 ~]# gluster peer probe centos83-2<br> [root@centos83-1 ~]# gluster peer status<br> Number of Peers: 1</p>
<p> Hostname: centos83-2<br> Uuid: b07d3d6e-4d6e-42a9-ad21-018223843fd5<br> State: Peer in Cluster (Connected)</p>
</li>
<li><p>To create brick on the first server:</p>
<p> [root@centos83-1 ~]# lsblk | egrep “NAME|sdb”<br> NAME               MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT<br> sdb                  8:16   0    1T  0 disk</p>
<p> [root@centos83-1 ~]# pvcreate &#x2F;dev&#x2F;sdb<br> [root@centos83-1 ~]# vgcreate vg_bricks &#x2F;dev&#x2F;sdb<br> [root@centos83-1 ~]# lvcreate -L 800g -n gfslv1 vg_bricks<br> [root@centos83-1 ~]# mkfs.xfs &#x2F;dev&#x2F;vg_bricks&#x2F;gfslv1<br> [root@centos83-1 ~]# mkdir -p &#x2F;bricks&#x2F;vm1_brick1<br> [root@centos83-1 ~]# vim &#x2F;etc&#x2F;fstab<br> &#x2F;dev&#x2F;vg_bricks&#x2F;gfslv1 &#x2F;bricks&#x2F;vm1_brick1        xfs     defaults        0 0<br> [root@centos83-1 ~]# mount -a<br> [root@centos83-1 ~]# df -h |grep gfs<br> &#x2F;dev&#x2F;mapper&#x2F;vg_bricks-gfslv1  800G  5.7G  794G   1% &#x2F;bricks&#x2F;vm1_brick1</p>
</li>
<li><p>To create brick on the second server:</p>
<p> [root@centos83-2 ~]# lsblk | egrep “NAME|sdb”<br> NAME               MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT<br> sdb                  8:16   0    1T  0 disk</p>
<p> [root@centos83-2 ~]# pvcreate &#x2F;dev&#x2F;sdb<br> [root@centos83-2 ~]# vgcreate vg_bricks &#x2F;dev&#x2F;sdb<br> [root@centos83-2 ~]# lvcreate -L 800g -n gfslv1 vg_bricks<br> [root@centos83-2 ~]# mkfs.xfs &#x2F;dev&#x2F;vg_bricks&#x2F;gfslv1<br> [root@centos83-2 ~]# mkdir -p &#x2F;bricks&#x2F;vm2_brick1<br> [root@centos83-2 ~]# vim &#x2F;etc&#x2F;fstab<br> &#x2F;dev&#x2F;vg_bricks&#x2F;gfslv1 &#x2F;bricks&#x2F;vm2_brick1        xfs     defaults        0 0<br> [root@centos83-2 ~]# mount -a<br> [root@centos83-2 ~]# df -h |grep gfs<br> &#x2F;dev&#x2F;mapper&#x2F;vg_bricks-gfslv1  800G  5.7G  794G   1% &#x2F;bricks&#x2F;vm2_brick1</p>
</li>
<li><p>To create distributed volume with the two bricks which are created on the two nodes:</p>
<p> [root@centos83-1 ~]# gluster volume create gv0 centos83-1:&#x2F;bricks&#x2F;vm1_brick1&#x2F;gv0 centos83-2:&#x2F;bricks&#x2F;vm2_brick1&#x2F;gv0<br> [root@centos83-1 ~]# gluster volume start gv0</p>
</li>
<li><p>To verify the volume status:</p>
<p> [root@centos83-1 ~]#  gluster volume info gv0</p>
<p> Volume Name: gv0<br> Type: Distribute<br> Volume ID: ee08d16a-f940-4ec2-aba8-5f1fcfe41bd4<br> Status: Started<br> Snapshot Count: 0<br> Number of Bricks: 2<br> Transport-type: tcp<br> Bricks:<br> Brick1: centos83-1:&#x2F;bricks&#x2F;vm1_brick1&#x2F;gv0<br> Brick2: centos83-2:&#x2F;bricks&#x2F;vm2_brick1&#x2F;gv0<br> Options Reconfigured:<br> storage.fips-mode-rchecksum: on<br> transport.address-family: inet<br> nfs.disable: on</p>
</li>
<li><p>To mount the distributed volume on one of the servers(treat it as client for simple demonstration):</p>
<p> [root@centos83-1 ~]# mkdir &#x2F;testmnt<br> [root@centos83-1 ~]# mount -t glusterfs centos83-2:&#x2F;gv0 &#x2F;testmnt<br> [root@centos83-1 ~]# df -h | grep testmnt<br> centos83-2:&#x2F;gv0               1.6T   28G  1.6T   2% &#x2F;testmnt</p>
</li>
</ol>
<p>As shown above, the usable storage size is the sum of the brick size from two nodes.</p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul>
<li><a target="_blank" rel="noopener" href="https://docs.gluster.org/en/latest/Administrator-Guide/GlusterFS-Introduction/">https://docs.gluster.org/en/latest/Administrator-Guide/GlusterFS-Introduction/</a></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.flamingbytes.com/blog/cbt-changed-block-tracking/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/logo/FlamingBytes-icon-64x64-1.png">
      <meta itemprop="name" content="relentlesstorm">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FlamingBytes">
      <meta itemprop="description" content="Stay hungry, stay foolish">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | FlamingBytes">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/blog/cbt-changed-block-tracking/" class="post-title-link" itemprop="url">CBT - Changed Block Tracking</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-02-26 08:00:00" itemprop="dateCreated datePublished" datetime="2021-02-26T08:00:00-08:00">2021-02-26</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-10-22 11:28:20" itemprop="dateModified" datetime="2023-10-22T11:28:20-07:00">2023-10-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Tech/" itemprop="url" rel="index"><span itemprop="name">Tech</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Tech/Big-Data/" itemprop="url" rel="index"><span itemprop="name">Big Data</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Changed Block Tracking is an incremental backup technology for virtual machines. It helps create faster and smaller backups. It has the following advantages.</p>
<ul>
<li>Reduce backup time</li>
<li>Save disk space by only storing changed data to the previous backup</li>
</ul>
<p>Block changes are tracked in the virtualization layer, outside the virtual machines. During a backup, only the changed block since the last backup are transmitted. For VMware, the vSphere APIs can be used to request the VMkernel to return the changed blocks from the last snapshot backup. Microsoft provides Resilient Change Tracking(RCT) to provide the native CBT feature for Hyper-V.</p>
<p>Veritas NetBackup Accelerator reduces the backup time for VMware backups. NetBackup uses VMware Changed Block Tracking (CBT) to identify the changes that were made within a virtual machine. Only the changed data blocks are sent to the NetBackup media server, to significantly reduce the I&#x2F;O and backup time. The media server combines the new data with previous backup data and produces a traditional full NetBackup image that includes the complete virtual machine files.</p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul>
<li><a target="_blank" rel="noopener" href="https://kb.vmware.com/s/article/1020128">https://kb.vmware.com/s/article/1020128</a></li>
<li><a target="_blank" rel="noopener" href="https://www.ibm.com/support/knowledgecenter/SSERB6_8.1.2/ve.hv/c_ve_hv_ovw_rct.html">https://www.ibm.com/support/knowledgecenter/SSERB6_8.1.2&#x2F;ve.hv&#x2F;c_ve_hv_ovw_rct.html</a></li>
<li><a target="_blank" rel="noopener" href="https://www.veritas.com/support/en_US/doc/21902280-127283730-0/v77418244-127283730">https://www.veritas.com/support/en_US&#x2F;doc&#x2F;21902280-127283730-0&#x2F;v77418244-127283730</a></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="Previous page" aria-label="Previous page" href="/page/22/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/22/">22</a><span class="page-number current">23</span><a class="page-number" href="/page/24/">24</a><span class="space">&hellip;</span><a class="page-number" href="/page/27/">27</a><a class="extend next" rel="next" title="Next page" aria-label="Next page" href="/page/24/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2023</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">relentlesstorm</span>
  </div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/mist/" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>







  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>





</body>
</html>
